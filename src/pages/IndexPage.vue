<template>
  <q-page class="page-container">
    <div class="content">
      <div ref="titlePanel" class="titlePanel">
        <h1>Athena</h1>
        <h2>by BirefrigentAI</h2>
        <hr style="width: 35%; text-align: center; margin-top: 25px; color: #fff" />
      </div>

      <div ref="predictPanel" class="overlay scroll">
        <textarea class="input-box" ref="inputText" placeholder="Enter your text here"></textarea>
        <div class="square-button-container">
          <button @click="predict()" class="square-button" ref="predictButton">Detect AI</button>
        </div>

        <div ref="displayPredictionOverlayPanel" id="displayPredictionOverlayPanel">
          <div
            style="font-family: Calibri; font-size: 150%; position: absolute; top: 10%; left: 10%"
            @click="refresh()"
          >
            &#x21BB;
          </div>
          <div
            style="font-family: Calibri; font-size: 150%; position: absolute; top: 10%; right: 10%"
            @click="hidePredictionOverlay()"
          >
            [X]
          </div>
          <div ref="predictionText"></div>
        </div>
      </div>
      <div class="bottomPanel" ref="bottomPanel">
        <a href="#" ref="bottomPanelLink1" @click="bottomPanelClick(1)" style="text-align: left"
          >• About Athena</a
        >
        <a href="#" ref="bottomPanelLink2" @click="bottomPanelClick(2)" style="text-align: left"
          >• Intro to LLMs</a
        >
      </div>

      <div ref="aboutOverlayPanel" class="overlay scroll">
        <div class="overlay-panel-text">
          <div
            style="
              font-weight: bold;
              font-variant: small-caps;
              letter-spacing: 0.2em;
              font-size: 120%;
            "
          >
            About Athena
          </div>
          <hr style="width: 100%; text-align: left" />
          <p>
            <b>Athena</b> is an AI model designed and trained to detect text produced by other AI
            models. It was created by fine-tuning a
            <a href="https://huggingface.co/docs/transformers/model_doc/distilbert"
              >pre-trained large language model</a
            >
            on a dataset of 60,438 text samples. Of these, 25,180 samples were from human sources:
            <a href="https://en.wikipedia.org/wiki/Main_Page">Wikipedia</a>,
            <a href="https://ai.stanford.edu/~amaas/data/sentiment/">IMDB</a> and
            <a href="https://reddit.com">Reddit</a>. The other 35,254 samples were generated by
            large-language models which were prompted and guided to create text that matched the
            human samples in style and content: 25,184 generated by GPT models, and the rest by
            Claude and Gemini models.
          </p>
          <p>
            Once Athena learnt to distinguish the patterns in AI-generated text from human writing,
            it was tested on five sets of test texts covering six topics: <b>Politics</b>,
            <b>Sport</b>, <b>Culture</b>, <b>Lifestyle</b>, <b>Opinion</b> and <b>Science</b>. The
            human text came from <a href="https://theguardian.com">the Guardian </a> and scientific
            articles from the
            <a href="https://arxiv.org/archive/astro-ph"
              ><i>astrophysics</i> section of the ArXiV repository</a
            >, and the AI-generated text came from 13 different AI models that were instructed to
            imitate the human writers as closely as possible.
            <b><a href="#" @click="showTestResults()">Click here</a></b> to see the results of this
            evaluation in full.
          </p>
          <p>
            The model is fully open source, with the train and test data as well as the full code to
            create the model available on the
            <a href="https://github.com/tommyliphysics/athena-source">GitHub</a>. If you'd like to
            take a deep dive into the process of creating an AI detector, check out this
            <a
              href="https://medium.com/@tomrodolfolee/building-an-ai-detector-from-scratch-part-i-db72bc2bdadb"
              >series of articles on medium.com</a
            >.
          </p>
        </div>
      </div>

      <div ref="testResultsOverlayPanel" class="overlay">
        <div class="overlay-panel-text" ref="testResultsOverlayText">
          <div
            style="
              display: flex;
              flex-direction: row;
              justify-content: space-between;
              height: 5%;
              font-weight: bold;
              font-variant: small-caps;
              letter-spacing: 0.2em;
              font-size: 120%;
            "
          >
            <div><a href="#" @click="showPanel(2)">About Athena</a></div>
            <div ref="selectTestSetDropdown" class="select-test-set-dropdown">
              <div
                class="test-set-dropdown-option"
                v-for="(option, index) in testSetDropdownOptions"
                :key="index"
                ref="testSetDropdownOptionDivs"
                @click="testSetDropdownOptionClicked(index)"
              >
                {{ option }}
              </div>
            </div>
          </div>
          <hr style="width: 100%; text-align: left" />
          <div style="display: block; max-width: 95%" ref="testResultsExplainText"></div>
          <div class="test-results-table-div scroll" ref="testResultsTable">
            <table style="width: 100%">
              <thead>
                <tr>
                  <th>Model</th>
                  <th>Total samples</th>
                  <th>Predicted AI</th>
                  <th>Predicted human</th>
                </tr>
              </thead>

              <tr
                ref="testResultsTableData"
                v-for="(model, index) in testSets[currentTestSetIdx].index.slice(1)"
                :key="index"
              >
                <td @click="showTestSample(index + 1, -1)"></td>
                <td @click="showTestSample(index + 1, -1)"></td>
                <td @click="showTestSample(index + 1, 1)"></td>
                <td @click="showTestSample(index + 1, 0)"></td>
              </tr>
            </table>
          </div>
        </div>
      </div>

      <div ref="testSampleOverlayPanel" id="testSampleOverlayPanel">
        <span style="position: absolute; top: 10px; right: 20px" @click="hideTestSampleOverlay()">
          <h3>[X]</h3>
        </span>
        <div
          style="
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            width: 100%;
            height: 100%;
          "
          class="scroll"
        >
          <div
            ref="explainTestSample"
            id="explainTestSample"
            @click="hideTestSampleOverlay()"
          ></div>
          <div>
            <p v-for="(para, index) in testSampleTextParas" :key="index">
              {{ para }}
            </p>
          </div>
        </div>
      </div>

      <div ref="courseOverlayPanel" class="overlay scroll white-background">
        <div class="overlay-panel-text">
          <div
            style="
              display: flex;
              flex-direction: row;
              justify-content: space-between;
              height: 5%;
              font-weight: bold;
              font-variant: small-caps;
              letter-spacing: 0.2em;
              font-size: 120%;
            "
          >
            <div>Intro to LLMs</div>
            <div>
              <a
                href="#"
                v-for="(item, index) in 6"
                :key="index"
                ref="showCourseItemLink"
                @click="showCourseText(index)"
                >•</a
              >
            </div>
          </div>
          <hr style="width: 100%; text-align: left" />
          <div style="display: none; flex-direction: column" ref="courseText1">
            <p><b>What is an LLM?</b></p>
            <p>
              Large language models (LLMs) grew out of efforts to create artificial intelligence
              capable of processing information in the form of natural human language. The
              predecessors of modern LLMs such as GPT, Deepseek, Claude and Gemini, which have
              existed since the early 2000s, performed tasks such as translation or classifying text
              into fixed categories. Today, LLMs have acquired the ability to respond to a user
              prompt with a text response that can provide information, solve problems, or even
              fulfil academic assignments such as creative writing or producing essays and research
              articles.
            </p>
            <p>
              An LLM can take on different personalities, whether artificial or imitative of human
              roles. By carefully wording the prompt, they can be guided to produce different styles
              of response. This is known as <b>prompt engineering.</b>
            </p>
          </div>
          <div style="display: none; flex-direction: column" ref="courseText2">
            <p><b>How do LLMs work?</b></p>
            <div class="course-text-2-layout">
              <div class="course-text-2-text">
                LLMs are powered by <b>neural networks:</b> computational structures that loosely
                imitate a biological nervous system. The fundamental units are
                <b>artificial neurons</b>, which are grouped into <b>layers</b>: the
                <i>input layer</i> receives information from the world, the
                <i>output layer</i> sends information into the world, and the
                <i>hidden layers</i> of the network perform internal processing. The neurons in each
                layer pass information to those in the next. A neural network derives its power from
                the numerous pathways that information can take as it streams from the input to the
                output layers.
              </div>
              <div class="course-text-2-animation">
                <img
                  src="images/nn_animation.gif"
                  alt="image of a basic neural network"
                  style="width: 100%; bottom: 0%"
                />
              </div>
            </div>
          </div>
          <div style="display: none; flex-direction: column" ref="courseText3">
            <p><b>How does an LLM interact with the user?</b></p>
            <p>
              The input of a generative text model is the prompt, which is encoded into numerical
              data by a process called <b>tokenization</b>. The input text is split into semantic
              units called <b>tokens</b>, which are either words or parts of words, and each token
              is assigned a unique numerical identifier. Take a look at the image below to see how
              the phrase "Generative artificial intelligence" is tokenized.
            </p>
            <p>
              The set of all tokens known to the model forms its vocabulary. The final output of the
              model is a sequence of tokens that constitute a meaningful and intelligent response to
              the prompt, but that text is <i>not</i> the output of the neural network. Instead,
              what the output layer of the neural network provides is a set of <b>probabilities</b>:
              for each token in the vocabulary, and for every position in the output sequence, the
              neural network provides the probability that that token will be found in that
              position.
            </p>
            <center>
              <img src="images/tokens_animation.gif" id="tokenAnimationGif" />
            </center>
          </div>
          <div style="display: none; flex-direction: column" ref="courseText4">
            <p><b>How does an LLM process text?</b></p>
            <p>
              When an LLM receives a prompt, it gets passed to the input layer, where it is
              transformed into numerical data that will flow through the hidden layers of the
              network. As the information is processed, the model will explore numerous possible
              responses, and assigns probabilities to each token in these responses which are then
              passed to the output layer. This process is called
              <b>inference</b>, and it's deterministic: if you provide the neural network the same
              prompt, it will give you the same probabilities every time. But the model needs to
              convert these <i>probabilities</i> into <i>text.</i>
            </p>
            <p>
              It could do this by simply choosing the most probable tokens, and then its response
              would be the same each time. This is not typically how LLMs are used, however: a model
              can randomly select tokens with lower probabilities than the most probable one, which
              allows it to vary its level of predictability and coherence, potentially creating an
              illusion of creativity.
            </p>
            <p>
              The image below illustrates this process, with four model responses to the prompt:
              <i>How do I make a chocolate soufflé?</i>. Each token in the response is coloured
              according to its probability (highly probable in blue, less probable in red).
            </p>
            <center>
              <img src="images/output_tokens_animation.gif" id="outputTokensAnimationGif" />
            </center>
          </div>
          <div style="display: none; flex-direction: column" ref="courseText5">
            <p><b>How does an LLM learn?</b></p>
            <p>
              Before an LLM can perform inference, it has to be trained: the connections between the
              neurons need to be forged. These are controlled by a set of numbers called the
              <b>model parameters</b>, which determine the amount of computing power required to run
              the model. The smallest LLMs have hundreds of millions of parameters, and can
              comfortably be run locally on consumer hardware without GPUs, while the largest have
              over a trillion and exact a heavy demand on computational resources. In order to
              encode an "understanding" of language into the pathways connecting the neurons, LLMs
              need to consume egregious volumes of human text. The large number of parameters and
              volume of training data are why these models are termed <i>large language models</i>.
            </p>
            <p>
              LLMs were never provided a vocabulary or taught what words mean. Instead, they
              acquired one by exposure to a natural language corpus (a large and diverse collection
              of text), which allowed them to learn the meaning of words by analysing how each one
              interacted with its context. LLMs have no pre-existing knowledge of linguistics,
              either: everything they know is derived from extracting statistical information from
              the training data. Without the training data, an LLM would have no understanding of
              language, no matter how complex it is or how many parameters it has. Its output would
              be simply be incoherent and meaningless.
            </p>
          </div>
          <div style="display: none; flex-direction: column" ref="courseText6">
            <p><b>Can LLM output be detected?</b></p>
            <p>
              While LLMs are designed to understand and produce text that sounds natural and human,
              they cannot yet perfectly imitate human writing. As more and more AI-generated text is
              studied, statistical patterns will emerge that do not exist in text created by human
              authors, as will a lack of certain human characteristics. A machine learning model can
              study these patterns and use them to estimate a <b>probability</b> that a text was
              AI-generated. If a text contains patterns similar to those found in AI-generated text,
              the model will report a high probability. But to say for certain whether any given
              text is AI-generated or human is impossible.
            </p>
            <p>
              To learn more about how <b>Athena</b> was designed and tested,
              <a href="#" @click="showAbout()" style="color: #001155"
                >click here to explore that in the app</a
              >, or
              <a
                href="https://medium.com/@tomrodolfolee/building-an-ai-detector-from-scratch-part-i-db72bc2bdadb"
                style="color: #001155"
                >check out my articles on medium.com</a
              >.
            </p>
          </div>
        </div>
      </div>
    </div>
  </q-page>
</template>

<script>
import clfResultsSoftvote from 'src/assets/softvote_clf_results.json'
import testSamples from 'src/assets/sample_texts_softvote.json'

export default {
  data() {
    return {
      testSetDropdownOptions: ['Politics', 'Sport', 'Culture', 'Lifestyle', 'Opinion', 'Science'],
      panels: [],
      showPredictAboutCourse: 1,
      showTestSetDropdown: false,
      serverStatus: true,
      currentTestSetIdx: 0,
      courseTexts: [],
      testSets: [
        clfResultsSoftvote.softvote.politics,
        clfResultsSoftvote.softvote.sports,
        clfResultsSoftvote.softvote.culture,
        clfResultsSoftvote.softvote.lifestyle,
        clfResultsSoftvote.softvote.opinion,
        clfResultsSoftvote.softvote.science,
      ],
      sampleTexts: [
        testSamples.politics,
        testSamples.sports,
        testSamples.culture,
        testSamples.lifestyle,
        testSamples.opinion,
        testSamples.science,
      ],
      testSampleTextParas: [],
    }
  },

  mounted() {
    this.$refs.titlePanel.classList.add('loaded')
    this.checkStatus()
    setTimeout(() => {
      this.$refs.titlePanel.classList.add('move-up')
      this.$refs.bottomPanel.classList.add('loaded')

      let hash = window.location.hash.split('#')
      console.log('Hash is: ', hash)
      if (hash[hash.length - 1] == '/About') {
        this.showAbout()
      } else {
        this.showPanel(1)
      }
    }, 1000)
    this.panels = [
      this.$refs.titlePanel,
      this.$refs.predictPanel,
      this.$refs.aboutOverlayPanel,
      this.$refs.testResultsOverlayPanel,
      this.$refs.courseOverlayPanel,
    ]
    this.courseTexts = [
      this.$refs.courseText1,
      this.$refs.courseText2,
      this.$refs.courseText3,
      this.$refs.courseText4,
      this.$refs.courseText5,
      this.$refs.courseText6,
    ]
  },

  methods: {
    showPanel(j) {
      for (let i = 1; i < this.panels.length; ++i) {
        if (i == j) {
          this.panels[i].classList.add('active')
        } else {
          this.panels[i].classList.remove('active')
        }
      }
      this.$refs.testResultsTable.classList.remove('active')
    },

    checkStatus() {
      var xhr = new XMLHttpRequest()
      xhr.open('POST', 'https://yg8q32yhcc.execute-api.us-east-1.amazonaws.com/athena', true)
      //xhr.open('POST', 'http://127.0.0.1:5000/athena', true)
      xhr.setRequestHeader('Content-Type', 'application/json')
      xhr.onreadystatechange = function () {
        if (xhr.readyState === XMLHttpRequest.DONE) {
          this.$nextTick(() => {
            if (xhr.status === 200) {
              console.log(xhr.responseText)
            } else {
              console.error('Server is down:', xhr.status)
            }
          })
        }
      }.bind(this)

      xhr.onerror = function () {
        console.error('Server is down:', xhr.status)
      }

      xhr.send()
    },

    predict() {
      var xhr = new XMLHttpRequest()
      this.$refs.predictButton.classList.add('loading')
      //xhr.open('POST', 'http://127.0.0.1:5000/athena/predict', true)
      xhr.open(
        'POST',
        'https://yg8q32yhcc.execute-api.us-east-1.amazonaws.com/athena/predict',
        true,
      )
      xhr.setRequestHeader('Content-Type', 'application/json')
      xhr.onreadystatechange = () => {
        if (xhr.readyState === XMLHttpRequest.DONE) {
          if (xhr.status === 200) {
            var predictionsRecv = JSON.parse(xhr.responseText)
            this.$refs.displayPredictionOverlayPanel.classList.add('active')
            if (predictionsRecv['AI'] > predictionsRecv['human']) {
              this.$refs.predictionText.innerHTML = `<b>${predictionsRecv['AI']}%</b> probability this is AI-generated`
              this.$refs.displayPredictionOverlayPanel.classList.add('AI')
              this.$refs.displayPredictionOverlayPanel.classList.remove('human')
            } else {
              this.$refs.predictionText.innerHTML = `<b>${predictionsRecv['human']}%</b> probability this is human`
              this.$refs.displayPredictionOverlayPanel.classList.add('human')
              this.$refs.displayPredictionOverlayPanel.classList.remove('AI')
            }
            this.$refs.predictButton.classList.remove('loading')
          } else {
            console.error('Request failed:', xhr.status)
          }
        }
      }
      xhr.send(JSON.stringify({ text: this.$refs.inputText.value }))
    },
    refresh() {
      this.$refs.inputText.value = ''
      this.hidePredictionOverlay()
    },
    hidePredictionOverlay() {
      this.$refs.displayPredictionOverlayPanel.classList.remove('active')
    },

    bottomPanelClick(linkID) {
      switch (this.showPredictAboutCourse) {
        case 1: // showing predict: link 1 is "about", link 2 is "course"
          if (linkID == 1) {
            this.showAbout()
          } else {
            this.showCourse()
          }
          break
        case 2: // showing About: link 1 is "predict", link 2 is "course"
          if (linkID == 1) {
            this.showPredict()
          } else {
            this.showCourse()
          }
          break
        case 3: // showing course: link 1 is "predict", link 2 is "about"
          if (linkID == 1) {
            this.showPredict()
          } else {
            this.showAbout()
          }
          break
      }
    },

    showPredict() {
      this.showPanel(1)
      this.$refs.bottomPanelLink1.innerHTML = '• About Athena'
      this.$refs.bottomPanelLink2.innerHTML = '• Intro to LLMs'
      this.showPredictAboutCourse = 1
    },

    showAbout() {
      this.showPanel(2)
      this.$refs.bottomPanelLink1.innerHTML = '• Detect AI'
      this.$refs.bottomPanelLink2.innerHTML = '• Intro to LLMs'
      this.showPredictAboutCourse = 2
    },
    showCourse() {
      this.showPanel(4)
      this.$refs.bottomPanelLink1.innerHTML = '• Detect AI'
      this.$refs.bottomPanelLink2.innerHTML = '• About Athena'
      this.showPredictAboutCourse = 3
      this.showCourseText(0)
    },

    toggleTestSetDropdownMenu() {
      let num_options = 6
      if (this.showTestSetDropdown) {
        for (let i = 1; i < num_options; i += 2) {
          this.$refs.testSetDropdownOptionDivs[i].classList.remove('light-background')
        }
        for (let i = 2; i < num_options; i += 2) {
          this.$refs.testSetDropdownOptionDivs[i].classList.remove('dark-background')
        }
        this.showTestSetDropdown = false
      } else {
        for (let i = 1; i < num_options; i += 2) {
          this.$refs.testSetDropdownOptionDivs[i].classList.add('light-background')
        }
        for (let i = 2; i < num_options; i += 2) {
          this.$refs.testSetDropdownOptionDivs[i].classList.add('dark-background')
        }
        this.showTestSetDropdown = true
      }
    },

    testSetDropdownOptionClicked(index) {
      this.toggleTestSetDropdownMenu()
      if (index > 0) {
        this.showTestSet(index)
      }
    },

    showTestResults() {
      this.showPanel(3)
      this.showTestSet(0)
      this.$refs.testSetDropdownOptionDivs[0].classList.add('first')
    },

    showTestSet(idx) {
      this.currentTestSetIdx = idx
      let currentTestSetName = this.testSetDropdownOptions[idx]
      let currentTestSet = this.testSets[this.currentTestSetIdx].data
      let predHuman = Math.round(currentTestSet[0][0] * currentTestSet[0][1])
      let AITestSize = currentTestSet.slice(1).map((row) => row.reduce((a, b) => a + b, 0))[0]

      let text = ''
      if (idx < 6) {
        text += `The <b>${currentTestSetName}</b> test set consisted of ${currentTestSet[0][0]} articles from the <i>${currentTestSetName}</i> section of the Guardian and ${AITestSize} AI-generated samples.`
      } else {
        text += `The <b>Science</b> test set consisted of ${currentTestSet[0][0]} abstracts of scientific articles from the ArXiV repository and ${AITestSize} AI-generated samples.`
      }

      text += ` Of the human texts, ${predHuman} were incorrectly classified as AI. For each of the AI models, the table below shows the total number of text samples, the fraction of these that Athena correctly identified as AI-generated, and the fraction that were incorrectly identified as human. Click on a cell below to see a sample from this dataset.`

      this.$refs.testSetDropdownOptionDivs[0].innerHTML = currentTestSetName
      let k = 0
      for (let j = 1; j < 6; j++) {
        if (k == idx) {
          k++
        }
        this.$refs.testSetDropdownOptionDivs[j].innerHTML = this.testSetDropdownOptions[k]
        k++
      }

      for (let j = 0; j < 6; j++) {
        this.testSetDropdownOptions[j] = this.$refs.testSetDropdownOptionDivs[j].innerHTML
      }

      const words = text.split(' ')
      let j = 0
      this.$refs.testResultsExplainText.innerHTML = ''

      for (let m = 0; m < this.$refs.testResultsTableData.length; ++m) {
        for (let c = 0; c <= 3; ++c) {
          this.$refs.testResultsTableData[m].children[c].textContent = ''
        }
      }

      const intervalUnscrollWords = setInterval(() => {
        if (j < words.length) {
          this.$refs.testResultsExplainText.innerHTML += (j > 0 ? ' ' : '') + words[j]
          j++
        } else {
          clearInterval(intervalUnscrollWords)
          let m = 0
          const intervalUnscrollTable = setInterval(() => {
            if (m < this.$refs.testResultsTableData.length - 1) {
              this.$refs.testResultsTableData[m].children[0].textContent =
                this.testSets[this.currentTestSetIdx].index[m + 1]

              this.$refs.testResultsTableData[m].children[1].textContent =
                this.testSets[this.currentTestSetIdx].data[m + 1][0]
              for (let c = 1; c <= 2; ++c) {
                this.$refs.testResultsTableData[m].children[c + 1].textContent =
                  this.testSets[this.currentTestSetIdx].data[m + 1][c].toFixed(4)
              }
              m++
            } else {
              clearInterval(intervalUnscrollTable)
            }
          }, 600 / this.$refs.testResultsTableData.length)
        }
      }, 600 / words.length)

      this.$refs.testResultsTable.classList.add('active')
    },

    showTestSample(modelIdx, acc) {
      let corr = ''
      switch (acc) {
        case 1:
          corr = 'correct'
          break
        case 0:
          corr = 'incorrect'
          break
        case -1:
          corr = Math.random() > 0.5 ? 'correct' : 'incorrect'
          break
      }
      let currentTestSet = this.testSets[this.currentTestSetIdx]
      let samplesList =
        this.sampleTexts[this.currentTestSetIdx][currentTestSet.index[modelIdx]][corr]

      this.testSampleTextParas =
        samplesList[Math.floor(Math.random() * samplesList.length)].split('\n\n')
      this.$refs.testSampleOverlayPanel.classList.add('active')
      if (corr == 'correct') {
        this.$refs.explainTestSample.classList.remove('incorrect-prediction')
        this.$refs.explainTestSample.classList.add('correct-prediction')
        this.$refs.explainTestSample.innerHTML = `${currentTestSet.index[modelIdx]} (correct prediction)`
      } else {
        this.$refs.explainTestSample.classList.remove('correct-prediction')
        this.$refs.explainTestSample.classList.add('incorrect-prediction')
        this.$refs.explainTestSample.innerHTML = `${currentTestSet.index[modelIdx]} (incorrect prediction)`
      }

      this.$refs.testResultsOverlayText.classList.add('inactive')
    },

    hideTestSampleOverlay() {
      this.$refs.testSampleOverlayPanel.classList.remove('active')
      this.$refs.testResultsOverlayText.classList.remove('inactive')
    },

    showCourseText(idx) {
      for (let j = 0; j < this.courseTexts.length; ++j) {
        if (j == idx) {
          this.courseTexts[j].style.display = 'flex'
          this.$refs.showCourseItemLink[j].style.color = '#336600'
        } else {
          this.courseTexts[j].style.display = 'none'
          this.$refs.showCourseItemLink[j].style.color = '#00ffff'
        }
      }
    },
  },
}
</script>

<style>
.select-test-set-dropdown {
  display: flex;
  flex-direction: column;
  align-items: center;
  z-index: 1;
  line-height: 1.5em;
  width: 16ch;
  height: 9em;
}

.test-set-dropdown-option {
  display: none;
  width: 100%;
  text-align: center;
}

.test-set-dropdown-option.first {
  display: block;
}

.test-set-dropdown-option.light-background {
  display: block;
  background-color: rgba(200, 200, 255, 0.8);
  color: rgb(15, 25, 50);
}

.test-set-dropdown-option.dark-background {
  display: block;
  background-color: rgba(200, 255, 200, 0.8);
  color: rgb(15, 50, 25);
}

.test-set-dropdown-option:hover {
  background-color: rgba(150, 200, 255, 0.9);
  color: rgb(15, 25, 50);
}

#testSampleOverlayPanel {
  flex-grow: 1;
  display: flex;

  flex-direction: column;
  justify-content: center;
  align-items: center;
  line-height: 1.4;
  box-sizing: border-box;
  overflow-x: hidden;

  position: absolute;
  top: 35%;
  left: 27.5%;
  width: 45%;
  height: 50%;
  z-index: 1000;

  background: rgba(255, 255, 255, 0.7);
  backdrop-filter: blur(10px);
  border-radius: 30px;
  box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);

  color: #222222;

  font-family: 'Times New Roman', serif;
  font-size: 1vw;

  visibility: hidden;
  opacity: 0;

  pointer-events: none;
}

#testSampleOverlayPanel.active {
  opacity: 1;
  visibility: visible;
  transition:
    opacity 2s ease,
    visibility 2s ease;
  pointer-events: auto;
}

#displayPredictionOverlayPanel {
  flex-grow: 1;
  display: flex;

  flex-direction: column;
  justify-content: center;
  align-items: center;
  line-height: 1.4;
  box-sizing: border-box;
  overflow-x: hidden;

  position: absolute;
  top: 15%;
  left: 27.5%;
  width: 45%;
  height: 27.5%;
  z-index: 1000;

  backdrop-filter: blur(10px);
  border-radius: 30px;
  box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);

  color: #222222;

  font-family: 'Times New Roman', serif;
  font-size: 1.25vw;

  visibility: hidden;
  opacity: 0;

  pointer-events: none;
}

#displayPredictionOverlayPanel.active {
  opacity: 1;
  visibility: visible;
  transition:
    opacity 2s ease,
    visibility 2s ease;
  pointer-events: auto;
}

#displayPredictionOverlayPanel.human {
  background: linear-gradient(45deg, rgba(25, 125, 225, 0.4), rgba(25, 225, 125, 0.1));
}

#displayPredictionOverlayPanel.AI {
  background: linear-gradient(45deg, rgba(125, 25, 125, 0.7), rgba(225, 25, 25, 0.3));
}

.course-text-2-layout {
  display: flex;
  flex-direction: row;
  gap: 5%;
  width: 100%;
}
.course-text-2-animation {
  width: 40%;
}

.course-text-2-text {
  width: 55%;
}

@media (max-aspect-ratio: 16/16) {
  #testSampleOverlayPanel {
    top: 25%;
    left: 15%;
    width: 70%;
    height: 55%;
    z-index: 1000;

    font-size: 3vw;
  }

  #displayPredictionOverlayPanel {
    font-size: 4vw;
    width: 90%;
    left: 5%;
    height: 20%;
  }
  .course-text-2-layout {
    flex-direction: column;
  }
  .course-text-2-text {
    width: 100%;
    margin-bottom: 10%;
  }
}

@media (max-aspect-ratio: 9/16) {
  .course-text-2-animation {
    width: 90%;
    margin: 0px auto;
  }
}

@media (min-aspect-ratio: 9/16) and (max-aspect-ratio: 16/16) {
  .course-text-2-animation {
    width: 50%;
    margin: 0px auto;
  }
}

#explainTestSample {
  display: flex;
  align-items: center;
  /*  font-family: 'Calibri', sans-serif;*/
  font-weight: bold;
  font-size: 100%;
  margin: 0px auto;
  padding-bottom: 5px;
  font-variant: small-caps;
  letter-spacing: 0.1rem;
  text-align: center;
}
#explainTestSample.correct-prediction {
  color: rgb(0, 95, 0);
}
#explainTestSample.incorrect-prediction {
  color: rgb(95, 0, 0);
}

#tokenAnimationGif {
  width: 90%;
  bottom: 0%;
  margin-top: 5%;
}

#outputTokensAnimationGif {
  width: 90%;
  bottom: 0%;
  margin-top: 5%;
}

@media (max-aspect-ratio: 16/16) {
  #tokenAnimationsImg {
    width: 100%;
    bottom: 0%;
    margin-top: 5%;
  }
  #outputTokensAnimationGif {
    width: 100%;
    bottom: 0%;
    margin-top: 5%;
  }
}
</style>
