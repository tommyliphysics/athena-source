{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXOBng14cYfr"
   },
   "source": [
    "# Building an AI-detector: fine-tuning DistilBERT with Keras (GPT only)\n",
    "\n",
    "In this notebook I'll go step-by-step through the process of building an AI detector by fine-tuning a pre-trained LLM ([DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)). The training data consists of human text samples from [English-language Wikipedia](https://en.wikipedia.org), [the IMDB review dataset](https://ai.stanford.edu/~amaas/data/sentiment/) from Stanford AI labs, and [Reddit](https://reddit.com), and AI text generated by gpt-4o and gpt-4o-mini.\n",
    "\n",
    "## Install and import dependencies\n",
    "\n",
    "First, we have to import the necessary libraries, making sure the latest version of the Huggingface \"transformers\" library is installed and is compatible with keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:21:15.844876Z",
     "iopub.status.busy": "2025-04-12T05:21:15.843777Z",
     "iopub.status.idle": "2025-04-12T05:21:36.002663Z",
     "shell.execute_reply": "2025-04-12T05:21:36.001210Z",
     "shell.execute_reply.started": "2025-04-12T05:21:15.844835Z"
    },
    "id": "9dGU_aCwcbAW",
    "outputId": "7cb6895d-943e-4ab0-abf0-e8bca5983f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:21:36.005283Z",
     "iopub.status.busy": "2025-04-12T05:21:36.004845Z",
     "iopub.status.idle": "2025-04-12T05:21:40.561732Z",
     "shell.execute_reply": "2025-04-12T05:21:40.560129Z",
     "shell.execute_reply.started": "2025-04-12T05:21:36.005249Z"
    },
    "id": "0DewwB8Nclz6",
    "outputId": "93fe3e74-bf6b-4faa-ccf7-a64de0b3bc4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:21:40.564040Z",
     "iopub.status.busy": "2025-04-12T05:21:40.563596Z",
     "iopub.status.idle": "2025-04-12T05:22:12.356654Z",
     "shell.execute_reply": "2025-04-12T05:22:12.355629Z",
     "shell.execute_reply.started": "2025-04-12T05:21:40.564004Z"
    },
    "id": "VPtmE-0UeulP"
   },
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k59AWv4iV4MQ"
   },
   "source": [
    "## Loading the training data\n",
    "\n",
    "Next, we load and explore the training data. The test data, which consists of texts from completely different sources to the training data, will not be seen by the model until the testing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:12.360353Z",
     "iopub.status.busy": "2025-04-12T05:22:12.359201Z",
     "iopub.status.idle": "2025-04-12T05:22:12.366435Z",
     "shell.execute_reply": "2025-04-12T05:22:12.364740Z",
     "shell.execute_reply.started": "2025-04-12T05:22:12.360318Z"
    },
    "id": "yLuVF3fHcId4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:12.368084Z",
     "iopub.status.busy": "2025-04-12T05:22:12.367735Z",
     "iopub.status.idle": "2025-04-12T05:22:13.702006Z",
     "shell.execute_reply": "2025-04-12T05:22:13.700676Z",
     "shell.execute_reply.started": "2025-04-12T05:22:12.368051Z"
    },
    "id": "qNTkA3KRc-qJ",
    "outputId": "46904d05-2a22-4e45-fc92-642ee1513599"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"human_train\",\n  \"rows\": 25180,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25180,\n        \"samples\": [\n          \"Greenpeace is an independent global campaigning network, founded in Canada in 1971 by a group of environmental activists. Greenpeace states its goal is to \\\"ensure the ability of the Earth to nurture life in all its diversity\\\" and focuses its campaigning on worldwide issues such as climate change, deforestation, overfishing, commercial whaling, genetic engineering, anti-war and anti-nuclear issues. It uses direct action, advocacy, research, and ecotage to achieve its goals.\\n\\nThe network comprises 26 independent national/regional organisations in over 55 countries across Europe, the Americas, Africa, Asia, Australia and the Pacific, as well as a coordinating body, Greenpeace International, based in Amsterdam, Netherlands.\\n\\nThe global network does not accept funding from governments, corporations, or political parties, relying on three million individual supporters and foundation grants. Greenpeace has a general consultative status with the United Nations Economic and Social Council and is a founding member of the INGO Accountability Charter, an international non-governmental organization that intends to foster accountability and transparency of non-governmental organizations.\\n\\nGreenpeace is known for its nonviolent direct actions and has been described as one of the most visible environmental organizations in the world. It has raised environmental issues to public knowledge, and influenced both the private and the public sector. The organization has received criticism; it was the subject of an open letter from more than 100 Nobel laureates urging Greenpeace to end its campaign against genetically modified organisms (GMOs). The organization's direct actions have sparked legal actions against Greenpeace activists, such as fines and suspended sentences for destroying a test plot of genetically modified wheat and, according to the Peruvian Government, damaging the Nazca Lines, a UN World Heritage site.\",\n          \"This didn't really happen today, more like over the course of the past 4 years. This is a throwaway because I'm very embarrassed. Sorry about formatting, I'm typing this on mobile. My girlfriend of 3 years passed away in a car accident about 4 years ago. It was a horrible event and I still haven't been able to get back into the game since. I was and still am very much in love with her. Now to the fuck up.\\n\\nMy favorite possession of all time is her pillow. It smells like her, and I usually sleep with it every night. I haven't washed it out of fear of losing the smell (I know, gross but I don't think straight anymore). I hold it and hug it and it makes me feel warm inside. But this morning when I went for a particularly long morning run I started smelling the smell. Really strong. It confused me but I wasn't going to start complaining.\\n\\nThis morning, about 20 minutes ago I arrived back home and went to change out of my workout clothes. And the smell grew more pungent. This was the moment I realized that after 4 years of sleeping with her pillow, I got it all dirty and smelly and that was the smell my brain now associates with her. I'm embarrassed and distraught that the smell I thought was hers has transformed into my sleep sweat.\\n\\nTL;DR- Slept with my passed away girlfriends pillow for 4 years, and have fallen in love with my man sweat.\\n\\nEdit: I would reply to all of you if I could, but today has been very emotionally taxing. Thanks for all your kind words.\",\n          \"Nanyang Technological University (NTU) is a public research university in Singapore. Founded in 1981, it is also the second oldest autonomous university in the country.\\n\\nThe university is organised across numerous colleges and schools, including the College of Engineering, College of Science, Nanyang Business School, Lee Kong Chian School of Medicine, College of Humanities, Arts and Social Sciences, Graduate College, National Institute of Education, and S. Rajaratnam School of International Studies. NTU is also home to several Research Centres of Excellence such as the Earth Observatory of Singapore and Singapore Centre on Environmental Life Sciences Engineering. NTU's main campus covers 200 hectares (490 acres) of land, making it the largest university campus in Singapore.\\n\\nThe primary campus grounds are located in the western part of Singapore, along 50 Nanyang Avenue. It also has two other campuses in Singapore's healthcare and start-up districts, Novena and one-north respectively. As a large, comprehensive, university, it has 34,384 enrolled students, and 7,613 faculty and staff as of 2021.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"Reddit (r/inlaws)\",\n          \"Reddit (r/parenting)\",\n          \"English Wikipedia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "human_train"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d2754c03-ddda-41b6-a0d2-2c1475766362\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Mathison Turing (; 23 June 1912 – 7 June ...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Dewey Watson (born April 6, 1928) is an ...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry George Drickamer (November 19, 1918 – Ma...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony Stephen Fauci  ( FOW-chee; born Decemb...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles Hard Townes (July 28, 1915 – January 2...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25175</th>\n",
       "      <td>I’ve been reading through AITA and found a pos...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>So, my mom bakes cakes and she got an order t...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25177</th>\n",
       "      <td>My brother is 16 and has Down Syndrome. For a ...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25178</th>\n",
       "      <td>With the news of Bill and Melinda Gates divorc...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25179</th>\n",
       "      <td>I love my girlfriend and I always have. We've ...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25180 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2754c03-ddda-41b6-a0d2-2c1475766362')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d2754c03-ddda-41b6-a0d2-2c1475766362 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d2754c03-ddda-41b6-a0d2-2c1475766362');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-15b14d17-a4c0-4cbe-9c3b-80fca6b72b86\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15b14d17-a4c0-4cbe-9c3b-80fca6b72b86')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-15b14d17-a4c0-4cbe-9c3b-80fca6b72b86 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_2aef4ede-c5fb-4de4-9126-f597833b0f74\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('human_train')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_2aef4ede-c5fb-4de4-9126-f597833b0f74 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('human_train');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Alan Mathison Turing (; 23 June 1912 – 7 June ...   \n",
       "1      James Dewey Watson (born April 6, 1928) is an ...   \n",
       "2      Harry George Drickamer (November 19, 1918 – Ma...   \n",
       "3      Anthony Stephen Fauci  ( FOW-chee; born Decemb...   \n",
       "4      Charles Hard Townes (July 28, 1915 – January 2...   \n",
       "...                                                  ...   \n",
       "25175  I’ve been reading through AITA and found a pos...   \n",
       "25176   So, my mom bakes cakes and she got an order t...   \n",
       "25177  My brother is 16 and has Down Syndrome. For a ...   \n",
       "25178  With the news of Bill and Melinda Gates divorc...   \n",
       "25179  I love my girlfriend and I always have. We've ...   \n",
       "\n",
       "                      source  \n",
       "0          English Wikipedia  \n",
       "1          English Wikipedia  \n",
       "2          English Wikipedia  \n",
       "3          English Wikipedia  \n",
       "4          English Wikipedia  \n",
       "...                      ...  \n",
       "25175  Reddit (r/OffMyChest)  \n",
       "25176  Reddit (r/OffMyChest)  \n",
       "25177  Reddit (r/OffMyChest)  \n",
       "25178  Reddit (r/OffMyChest)  \n",
       "25179  Reddit (r/OffMyChest)  \n",
       "\n",
       "[25180 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_train = pd.read_csv('human_train_gpt_only.csv')\n",
    "human_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9jl1wKwYPaq"
   },
   "source": [
    "The human samples are labelled with the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:13.703830Z",
     "iopub.status.busy": "2025-04-12T05:22:13.703320Z",
     "iopub.status.idle": "2025-04-12T05:22:13.718663Z",
     "shell.execute_reply": "2025-04-12T05:22:13.717569Z",
     "shell.execute_reply.started": "2025-04-12T05:22:13.703793Z"
    },
    "id": "-JTBV0IiYMz9",
    "outputId": "b953e170-c2bd-40b5-9205-23ea05011bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English Wikipedia', 'IMDB review', 'Reddit (r/AmItheAsshole)',\n",
       "       'Reddit (r/relationship_advice)', 'Reddit (r/dating_advice)',\n",
       "       'Reddit (r/tifu)', 'Reddit (r/TrueOffMyChest)',\n",
       "       'Reddit (r/confessions)', 'Reddit (r/FML)', 'Reddit (r/parenting)',\n",
       "       'Reddit (r/inlaws)', 'Reddit (r/OffMyChest)'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_train['source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:13.720714Z",
     "iopub.status.busy": "2025-04-12T05:22:13.720169Z",
     "iopub.status.idle": "2025-04-12T05:22:13.743088Z",
     "shell.execute_reply": "2025-04-12T05:22:13.741594Z",
     "shell.execute_reply.started": "2025-04-12T05:22:13.720652Z"
    },
    "id": "z0117PHMYTbH",
    "outputId": "e25e82d9-7c22-4e65-872b-13e3cbb57d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: IMDB review, text: I first saw \"Signs of Life\" on PBS as an American Playhouse presentation. It's a wonderfully written, ensemble production with terrific performances by Michael Lewis as Joey and Vincent D'Onofrio as his brother, Daryl. Arthur Kennedy, in one of his last roles, is also excellent as an aging shipbuilder whose family business is about to close. The rest of the cast which includes Beau Bridges, Kathy Bates and Mary-Louise Parker give remarkable clarity and substance to their characters.\n",
      "\n",
      "The direction is subtle and effective. I've watched this movie several times over the years and would very much recommend it. A beautiful piece of filmmaking.\n",
      "********************\n",
      "Source: Reddit (r/AmItheAsshole), text: \n",
      "To start off I want to say that my husband (36M) has an old friend (33M) that he's known since highschool. they're inseperable and spend the entire week together. like they're really really close.\n",
      "\n",
      "My husband and I struggled with fertility issues for years. we recently started new method (IVF) in hopes to get at least one child together. Note that I saved for the majority of treatment while my husband only paid 2-3 thousands. We saved up for another round after the huge disappointment and heartbreak from failing the first time (that's just how it goes). This time I'd put all the money (including dad's inhertance) and my husband didn't pay a cent.\n",
      "\n",
      "\n",
      "Last week I found out that he secretly pulled out 7k (we had 11k in total). I was completely and utterly shocked I confronted him and he casually reminded me of how many times his best friend complained about his \"old junk\" car and he decided to \"lend\" him 7k to buy a decent car, his argument was that his friend would've done the same for him. I was beyond livid I asked if he really thought that was okay and he said that I shouldn't worry and guaranteed his friend will pay us back in time. I lost it on him and immediately demanded his friend to send the money back and threatened police involvement in case he refused. His friend immediately returned the money but told my husband about the polic thing and my husband came home and yelled at me calling me unhinged and selfish. I told him I saved up some of this money/used my inheritance for this treatment while he contributed nothing even though we're in this together. He \"corrected\" me saying I'm the one with the problem and he thought it's only fair that I \"make up\" for it by paying for the IVF myself. This hurt so badly and I couldn't argue anymore. He went to stay with his friend while constantly shaming me for how I treated them both and for the police invovlement like they stole from me or something.\n",
      "********************\n",
      "Source: IMDB review, text: Every American who thinks he or she understands World War Two should see this movie. Few Hollywood films about the war have defied the stereotype of Japanese soldiers as emotionless brutes obeying orders without thinking. We like to think that every Japanese man was ready and able to fight to the death, right up to the day we bombed Nagasaki. \"Fires on the Plain\" shows a different reality: troops pathetically undersupplied, demoralized and starved to the point of cannibalism. They euphemistically refer to human flesh as \"monkey meat.\" The movie and novel on which it was based also put to death the myth that Japanese soldiers all preferred death to surrender: They had good reason to believe that their enemies were in no mood to take prisoners. To me it raises a question most Americans would rather avoid: If the Japanese military was so beaten down at this point in the war, why was it necessary to nuke Hiroshima?\n",
      "********************\n",
      "Source: IMDB review, text: I loved this episode. It is so great that all 5 of them team up and stop LutherCorp and save the world. I also love this episode because Kyle Gallner (Bart Allen/Impulse) and Justin Hartley (Oliver Queen/Green Arrow) are guest starring in it!!! I just hope that Clark will join the Justice League and we'll get to follow this group of heroes across the globe!! =)It was really exciting and keeps viewers interested because of what will happen next. I think Chloe should also join the team as Watchtower, that would be such a coool thing for her to do besides the Daily Planet because she doesn't have super powers. Also, I want to find out what types of subjects Lex is going to use for 33.1, I wonder what other types of powers other people in the world have!!!\n",
      "********************\n",
      "Source: IMDB review, text: Mute Witness is a modest, yet very solid thriller that never really received the attention or good comments it deserves. The film  written and directed entirely by Anthony Waller  is a tense, action-packed thriller with black comedy aspects and horror influences. No pointless mumbo-jumbo or endless plot-twists",
      "just straight to the point mystery. Mute Witness handles about the vicious topic of `snuff'-movies and is effectively set in Russia. *** SPOILERS *** Since the production costs are cheaper there, a US film crew temporarily moves to Russia for shooting a horror film. An old hangar is used as film location. The female make-up artist of the team accidentally gets locked up overnight and while trying to find a way out, she witnesses the recordings of an authentic snuff-movie! She's caught and tries to escape but, since she's a mute, she can't cry for help and neither can she explain what she saw to the police properly. The girl's life is in real danger now, since there's a whole hidden network behind these snuff productions and they don't want the witnesses to be alive",
      " *** End Spoilers ***. Mute Witness contains multiple highly exiting action sequences and is rather bloody. Some of the mystery clues are effectively kept secret till the very end. Regarding the similar topic, I'd say it's definitely better than the more famous `8 mm', directed by Joel Schumacher and starring Nicolas Cage. The acting in Mute Witness isn't great, but the leading actress (who's Russian herself) looks really cute. Sir Alec Guinness makes a special appearance, too. And a very cool one, I may say. Surely recommended with guaranteed fun and scares.\n",
      "********************\n",
      "Source: English Wikipedia, text: Olympia (Modern Greek: Ολυμπία [oli(m)ˈbi.a]; Ancient Greek: Ὀλυμπία [olympí.aː]), officially Archaia Olympia (Greek: Αρχαία Ολυμπία lit. 'Ancient Olympia'), is a small town in Elis on the Peloponnese peninsula in Greece, famous for the nearby archaeological site of the same name. The site was a major Panhellenic religious sanctuary of ancient Greece, where the ancient Olympic Games were held every four years throughout classical antiquity, from the 8th century BC to the 4th century AD. They were restored on a global basis in 1894 in honor of the ideal of peaceful international contention for excellence.\n",
      "\n",
      "The sacred precinct, named the Altis, was primarily dedicated to Zeus, although other gods were worshipped there. The games conducted in his name drew visitors from all over the Greek world as one of a group of such \"Panhellenic\" centres, which helped to build the identity of the ancient Greeks as a nation. Despite the name, it is nowhere near Mount Olympus in northern Greece, where the twelve Olympians, the major deities of ancient Greek religion, were believed to live.\n",
      "\n",
      "Ancient history records that Pisa and Elis, other villages in the region, contended with Olympia for management of the precinct, and that Olympia won, implying that the village was not identical to the precinct. The putative location of the ancient village is the modern village, which appears to have been inhabited continuously since ancient times.\n",
      "\n",
      "The archaeological site held over 760 significant buildings, and ruins of many of these survive.\n",
      "\n",
      "Of special interest to Greeks is the Pelopion, tomb of the quasi-mythical king Pelops, who gives his name to the Peloponnese and was ancestor of Agamemnon and Menelaus, the Greek kings of the Trojan War. The tomb suggests that he may not have been entirely mythical.\n",
      "\n",
      "Another location that has a special interest to both ancients and moderns is the stadium. It is basically a field with start and end lines marked off by transverse curbing. The athletes entered under an archway of a vaulted corridor at the start. Spectators sat mainly on the field's sloping flanks. The length of this field became the standard stadion, an ancient Greek unit of distance, which appears in all the geographers. The stadium has been resurrected for Olympic use with no intentional alteration of the ancient topography. Transient stands are easily thrown up and removed.\n",
      "\n",
      "The first major games to have been played at the Olympia stadium were said to have first begun in the 720s. These prestigious ancient games took place during the festival of Zeus at Olympia. Olympia was a sanctuary, but it was within the independent state of Elis, and since the Eleans managed the games, there was sometimes bias. The famous Olympic truce only mandated safe passage for visitors and did not stop all wars in Greece or even at Olympia.\n",
      "\n",
      "The village services the adjacent archaeological site to the southeast. The Kladeos River forms the site's western border. Visitors walk over the bridge to find themselves in front of the main gate. Full visitation is an extensive walking event. Some excavation is in progress there frequently. Moveable artifacts for the most part have found a home in one of the site's three museums.\n",
      "********************\n",
      "Source: English Wikipedia, text: The University of New Mexico (UNM; Spanish: Universidad de Nuevo México)  is a public research university in Albuquerque, New Mexico, United States. Founded in 1889 by the New Mexico Territorial Legislature, it is the state's second oldest university, a flagship university in the state, and the largest by enrollment, with 22,630 students in 2023.\n",
      "\n",
      "UNM comprises twelve colleges and schools, including a medical school and the only law school in New Mexico. It offers 215 degree and certificate programs, including 94 baccalaureate, 71 master, and 37 doctoral degree programs. The main campus spans 800 acres (320 ha) in central Albuquerque, with branch campuses in Gallup, Los Alamos, Rio Rancho, Taos, and Los Lunas.\n",
      "\n",
      "UNM is classified among \"R1: Doctoral Universities - very high research activity\". According to the National Science Foundation, it spent over $243 million on research and development in 2021, ranking 103rd in the U.S. UNM is classified as a Hispanic-Serving Institution (HSI) by the U.S. Department of Education, with nearly half its students being Hispanic.\n",
      "\n",
      "UNM's 16 varsity sports programs, known as the Lobos, compete in NCAA Division I (FBS for football) and are members of the Mountain West Conference; the school has won national championships in skiing and cross country running. UNM's official colors are cherry and silver. The school has approximately 200,000 alumni worldwide.\n",
      "********************\n",
      "Source: English Wikipedia, text: The Fiat Tipo (codeproject Type 356, also known as the Fiat Egea (stylized as ÆGEA) in Turkey and Dodge Neon in Mexico and the Middle East) is a compact car. A three-box sedan version was unveiled at the 2015 Istanbul Motor Show in May 2015, and commenced sales in Turkey in October 2015. In 2016, it was followed by a hatchback and a station wagon version, for the European market. The Tipo is assembled at the Tofaş plant in Bursa, Turkey, by the Italian automaker Fiat and is built on the Fiat Small Wide LWB platform. It replaced the Bravo and Linea in the C-segment range. The Tipo was designed by Centro Stile Fiat in Mirafiori, Turin. In December 2015, the car won the 2016 Best Buy Car of Europe Award, from the Autobest jury made up of Europe's twenty-six leading journalists, from twenty-six different European countries.\n",
      "\n",
      "In February 2019, the 500,000th Fiat Tipo was produced at the Bursa plant, in Turkey. At the end of October 2020 (28th), a total of 670,000 units of Fiat Tipo had been produced and distributed in over 40 Countries around the world. In 2021, Fiat introduced a facelift to the Tipo with a new motor, new levels of security, technology and a new Cross version. The new change of this facelift introduced the new gasoline engines of the Global Small Engine (FireFly) family produced by FCA Poland Powertrain in Bielsko-Biała in only one version: 1.0 L Turbo 3-cylinder 120 hp with direct injection, Multiair system and GPF filter, the 1.0 L is available with a 5-speed manual transmission and front-wheel drive, this new motor is for the models Jeep Renegade, Fiat 500 and Fiat Tipo (2015).\n",
      "\n",
      "In March 2022, the new 1.5-liter GSE (Global Small Engine) T4, four-cylinder, 130 HP and 240 Nm of torque, also from the FireFly family, was introduced in Italy, Europe, Turkey and in the United Arab Emirates (like the previous 1.0 T3), Turbo petrol but with hybrid technology, combined with a 48V electric motor that integrates a small additional 15 kW unit, the latter installed in the new seven-speed dual-clutch DCT automatic transmission, capable of allowing a more silent start (100% electric) and to use the car in fully electric mode (e-launch), in parking maneuvers or in small forward movements at walking pace (e-queuing), such as when in queue in city traffic. This hybrid technology represented a step forward for Fiat, improving the efficiency and dynamics of the vehicle and allowing it to travel with the thermal engine switched off.\n",
      "\n",
      "The petrol engine, in fact, thanks to the electric one, can remain inactive up to 47% of the time. For this reason, the new 130 bhp 1.5-liter GSE T4 e-motor has been defined by experts in the field of automotive (not a mild-hybrid, introduced on the Fiat Panda and Fiat 500 only, but) a mini Full-hybrid or Middle-hybrid, (i.e. a via between a full-hybrid and a mild-hybrid), according to the hybrid cars of other brands such as Toyota, which was the first to introduce this technology in the automotive market. This new advanced hybrid engine, developed by the engineers of the FCA Group (also introduced on the new Alfa Romeo Tonale, on the Fiat 500X hybrid, as well as on the Jeep Renegade and Compass models), also allows an 11% reduction in CO2 compared to the previous version, with declared consumption, for the new Fiat Tipo hybrid, of just 4.7 l/ 100 km. In November 2022, the 1 million Tipo was produced at Bursa plant.\n",
      "********************\n",
      "Source: IMDB review, text: The main criticism of AT THE EARTH'S CORE is that it's cheap, the special effects are bad and so on and so forth. Yes, some of the special effects are painfully bad but what a lot of folks overlook about it is that it's actually quite fun, which is very important in my book.\n",
      "\n",
      "In comparison, just look at the latest STAR WARS films: they have the latest, greatest special effects created by the latest technological advances which are capable in creating stunning visual effects as far reaching as the human imagination can imagine and yet, with all the razzle dazzle, those films were as exciting as a funeral. As Yoda would say, Fun they're not! In other words, who cares if the FX aren't the greatest when the spirit of the film is fast-paced, humorous and clearly set on the side of action. I love everything about AT THE EARTH'S CORE: the contrast between stodgy Victorian England VS the wild other-worldly, colorful setting of Pellucidar, the cast of characters, the concept of a lost underground world, the telepathic Pterodactyls, the human slaves rebelling, Jubal the ugly one (lol!), the inspired teaming of Peter Cushing (who's great!) and Doug McClure, the excellent music (it's really good), cinematography by the amazing Alan Hume and last but not least, Caroline Munro. She's effing sexy in this movie. One of the sexiest B-movie babes ever captured on screen.\n",
      "\n",
      "Seriously, anyone who doesn't like this movie doesn't know what fun is. Gimme AT THE EARTH'S CORE over any turgid STAR WARS prequels any time! At least it has Caroline Munro, which no CGI fx can ever recreate.\n",
      "********************\n",
      "Source: IMDB review, text: Personally I couldn't get into 'This is Not a Love Song', its a brilliant film and there's a great story line to it, I just found myself checking the time on my phone every two minuets to see how much was left of the film.\n",
      "\n",
      "I love the relationship between Spike and Heaton, there that close they depend on each other to get along in life. At the same time I wish the relationship was more than what it is. Heaton is in love with spike, but Spike Ibsen't in love with Heaton, or he doesn't know how to love him. The acts of betrayal, on both parts, have a big effect on the two men. They are both devastated by the fact that the other ran away and abandoned them, at a time when they truly needed each other for survival.\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for idx, row in human_train.sample(10, random_state=623).iterrows():\n",
    "  print(f\"Source: {row['source']}, text: {row['text']}\")\n",
    "  print('*'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9emfY5W5YxPL"
   },
   "source": [
    "Let's now take a look at the AI samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:13.744713Z",
     "iopub.status.busy": "2025-04-12T05:22:13.744268Z",
     "iopub.status.idle": "2025-04-12T05:22:15.013008Z",
     "shell.execute_reply": "2025-04-12T05:22:15.011654Z",
     "shell.execute_reply.started": "2025-04-12T05:22:13.744644Z"
    },
    "id": "ZGfIVfFkWG9d",
    "outputId": "0799bcae-a5ea-4d19-f8d3-b18ae0811134"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"AI_train\",\n  \"rows\": 25184,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25184,\n        \"samples\": [\n          \"Greenpeace is a non-governmental environmental organization founded in 1971, known for its direct action, lobbying, and research efforts to address global environmental issues. Established in Vancouver, Canada, by a group of activists, including Irving Stowe and Dorothy Stowe, Greenpeace initially focused on opposing nuclear testing and promoting peace. Over the years, the organization has expanded its scope to tackle a wide range of environmental challenges, including climate change, deforestation, overfishing, and pollution.\\n\\nWith a presence in over 55 countries, Greenpeace has become one of the world's most recognized and influential environmental organizations. The organization employs a combination of grassroots activism, public campaigns, and strategic partnerships to raise awareness and advocate for sustainable practices. Known for its bold and sometimes controversial tactics, Greenpeace utilizes non-violent direct action to highlight environmental issues and hold corporations and governments accountable for their impact on the planet.\\n\\nGreenpeace\\u2019s mission is to ensure the ability of the Earth to nurture life in all its diversity and to promote solutions that are essential to a green and peaceful future. Through its campaigns, the organization aims to inspire individuals and communities to take action for a sustainable environment and to challenge the political and economic systems that contribute to environmental degradation.\",\n          \"I recently watched \\\"Star Trek\\\" (2009) and wow, what a ride! As someone who isn't a hardcore Trekkie, I was a bit apprehensive about diving into this franchise, but this movie really hooked me from the get-go.\\n\\nThe story kicks off with an intense backstory involving James T. Kirk and Spock that sets the stage for an exciting adventure. The action is top-notch, with some stunning visuals that really bring space to life. I especially loved the unique spin on time travel in the plot\\u2014it's creative and kept me on the edge of my seat!\\n\\nThe cast is fantastic. Chris Pine as Kirk and Zachary Quinto as Spock have great chemistry, which makes their on-screen friendship intriguing. They capture the essence of their characters while also bringing something fresh to the table. The supporting cast, including Zoe Saldana as Uhura and Karl Urban as Bones, add depth and charm that makes every scene entertaining.\\n\\nOne of my favorite aspects of this film is how it balances action, humor, and character development. I found myself laughing at many of the witty one-liners while still being emotionally invested in the characters' journeys. The film successfully sets up a new generation of \\\"Star Trek\\\" without alienating long-time fans (pun intended!).\\n\\nIf I have to nitpick, some plot points were a bit predictable, but honestly, it didn\\u2019t take away from my overall enjoyment. Plus, the epic soundtrack and direction kept everything feeling grand and inspiring.\\n\\nOverall, \\\"Star Trek\\\" (2009) is a thrilling reboot that opens the door for newcomers and satisfies long-time fans. I walked away with a smile and a newfound curiosity about the \\\"Star Trek\\\" universe. Definitely worth a watch!\\n\\nRating: 8/10 \\u2b50\\ufe0f\\ud83c\\udf1f\\ud83d\\ude80\",\n          \"Britney Jean Spears (born December 2, 1981) is an American singer, songwriter, dancer, and actress. Often referred to as the \\\"Princess of Pop,\\\" she is credited with influencing the revival of teen pop in the late 1990s and early 2000s. Spears gained immense popularity with her debut single \\\"...Baby One More Time\\\" in 1998, which became a global hit and catapulted her to fame. Over the years, she has released numerous chart-topping albums, including \\\"Oops!... I Did It Again,\\\" \\\"Britney,\\\" and \\\"In the Zone,\\\" solidifying her status as one of the best-selling music artists of all time.\\n\\nIn addition to her musical achievements, Spears has made headlines for her highly publicized personal life, including her struggles with mental health and a controversial conservatorship that lasted over a decade. Her experiences have sparked widespread discussions about celebrity culture, mental health awareness, and personal autonomy. Throughout her career, Spears has received numerous awards and accolades, including a Grammy Award, and has been recognized for her contributions to the music industry and popular culture.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16450,\n        \"samples\": [\n          \"Write a post in r/OffMyChest with the title: \\\"I would never talk to my mom that way!\\\" Cool, if I had your mom, I wouldn't have to, either\",\n          \"Write a post in r/dating_advice with the title: Anyone else feel immense anxiety when they start dating an actual nice person?\",\n          \"Write the introductory section to a Wikipedia page with the following title: College of Idaho\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"system\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"You are a wikipedia contributor.\",\n          \"You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\",\n          \"You are a redditor.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"gpt-4o\",\n          \"gpt-4o-mini\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35838775222655994,\n        \"min\": 0.0,\n        \"max\": 1.2,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          0.09,\n          0.43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Removed headers, replaced \\\"overworked freelance graphic designer\\\" with \\\"graphic designer\\\"\",\n          \"Removed headers, replaced \\\"an overworked freelance graphic designer\\\" with \\\"an independent single dad\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "AI_train"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-262acd94-a0ae-4068-995c-1d4c5345aaeb\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>system</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Turing (23 June 1912 – 7 June 1954) was a...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Dewey Watson (born April 6, 1920) is an ...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry George Drickamer (born [insert date of b...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony Stephen Fauci (born December 24, 1940)...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles H. Townes (July 28, 1915 – January 27,...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.03</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25179</th>\n",
       "      <td>I don’t even know where to begin, but I’ve got...</td>\n",
       "      <td>Write a post in r/OffMyChest with the title: C...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25180</th>\n",
       "      <td>So, I just got home from school and found out ...</td>\n",
       "      <td>Write a post in r/OffMyChest with the title: M...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25181</th>\n",
       "      <td>Hey everyone,\\n\\nI just wanted to take a momen...</td>\n",
       "      <td>Write a post in r/OffMyChest with the title: T...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.17</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25182</th>\n",
       "      <td>I’ve been sitting on this for a while now, and...</td>\n",
       "      <td>Write a post in r/OffMyChest with the title: N...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25183</th>\n",
       "      <td>Hi everyone,\\n\\nI wanted to take a moment to g...</td>\n",
       "      <td>Write a post in r/OffMyChest with the title: B...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.10</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25184 rows × 6 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-262acd94-a0ae-4068-995c-1d4c5345aaeb')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-262acd94-a0ae-4068-995c-1d4c5345aaeb button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-262acd94-a0ae-4068-995c-1d4c5345aaeb');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-76d22c11-3faa-44e3-9399-879359657e11\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76d22c11-3faa-44e3-9399-879359657e11')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-76d22c11-3faa-44e3-9399-879359657e11 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_2ee534af-b358-4140-8809-54042621d562\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('AI_train')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_2ee534af-b358-4140-8809-54042621d562 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('AI_train');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Alan Turing (23 June 1912 – 7 June 1954) was a...   \n",
       "1      James Dewey Watson (born April 6, 1920) is an ...   \n",
       "2      Harry George Drickamer (born [insert date of b...   \n",
       "3      Anthony Stephen Fauci (born December 24, 1940)...   \n",
       "4      Charles H. Townes (July 28, 1915 – January 27,...   \n",
       "...                                                  ...   \n",
       "25179  I don’t even know where to begin, but I’ve got...   \n",
       "25180  So, I just got home from school and found out ...   \n",
       "25181  Hey everyone,\\n\\nI just wanted to take a momen...   \n",
       "25182  I’ve been sitting on this for a while now, and...   \n",
       "25183  Hi everyone,\\n\\nI wanted to take a moment to g...   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      Write the introductory section to a Wikipedia ...   \n",
       "1      Write the introductory section to a Wikipedia ...   \n",
       "2      Write the introductory section to a Wikipedia ...   \n",
       "3      Write the introductory section to a Wikipedia ...   \n",
       "4      Write the introductory section to a Wikipedia ...   \n",
       "...                                                  ...   \n",
       "25179  Write a post in r/OffMyChest with the title: C...   \n",
       "25180  Write a post in r/OffMyChest with the title: M...   \n",
       "25181  Write a post in r/OffMyChest with the title: T...   \n",
       "25182  Write a post in r/OffMyChest with the title: N...   \n",
       "25183  Write a post in r/OffMyChest with the title: B...   \n",
       "\n",
       "                                 system        model  temperature  \\\n",
       "0      You are a wikipedia contributor.  gpt-4o-mini         0.22   \n",
       "1      You are a wikipedia contributor.  gpt-4o-mini         0.31   \n",
       "2      You are a wikipedia contributor.  gpt-4o-mini         0.54   \n",
       "3      You are a wikipedia contributor.  gpt-4o-mini         0.38   \n",
       "4      You are a wikipedia contributor.  gpt-4o-mini         0.03   \n",
       "...                                 ...          ...          ...   \n",
       "25179               You are a redditor.  gpt-4o-mini         1.11   \n",
       "25180               You are a redditor.  gpt-4o-mini         1.03   \n",
       "25181               You are a redditor.  gpt-4o-mini         1.17   \n",
       "25182               You are a redditor.  gpt-4o-mini         1.15   \n",
       "25183               You are a redditor.       gpt-4o         1.10   \n",
       "\n",
       "                                      cleaning  \n",
       "0      Removed headers and markdown formatting  \n",
       "1      Removed headers and markdown formatting  \n",
       "2      Removed headers and markdown formatting  \n",
       "3      Removed headers and markdown formatting  \n",
       "4      Removed headers and markdown formatting  \n",
       "...                                        ...  \n",
       "25179                          Removed headers  \n",
       "25180                          Removed headers  \n",
       "25181                          Removed headers  \n",
       "25182                          Removed headers  \n",
       "25183                          Removed headers  \n",
       "\n",
       "[25184 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_train = pd.read_csv('AI_train_gpt_only.csv')\n",
    "AI_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtVR-VF-eulR"
   },
   "source": [
    "We see that, in addition to the text samples, the file contains details of the prompt, model, temperature and cleaning. Let's explore these to get a better idea of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:15.014588Z",
     "iopub.status.busy": "2025-04-12T05:22:15.014192Z",
     "iopub.status.idle": "2025-04-12T05:22:15.025815Z",
     "shell.execute_reply": "2025-04-12T05:22:15.024435Z",
     "shell.execute_reply.started": "2025-04-12T05:22:15.014556Z"
    },
    "id": "zm9kBgZ6ZC-Q",
    "outputId": "a0a213ae-5f46-467c-c6c9-b9633c62c11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write an IMDB review for the following movie: Cars (2006)\n",
      " System: You are an amateur movie critic leaving an IMDB review. You aren't writing professionally, but you still put thought into your comments.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Big Daddy (1999)\n",
      " System: You are a casual moviegoer with no experience in creative writing who occasionally writes IMDB reviews while waiting for food to cook in the microwave.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Interquartile range\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Guardians of the Galaxy (2014)\n",
      " System: You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Ruthless People (1986)\n",
      " System: You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Catamaran\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Twilight (2008)\n",
      " System: You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\n",
      "********************\n",
      "Prompt: Write a post in r/relationship_advice with the title: My partner (30M) and I (27F) invited family friends (40F, 55M, 7-month-old baby), but they’ve already outstayed their welcome within 24 hours.\n",
      " System: You are a redditor.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Incredibles 2 (2018)\n",
      " System: You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\n",
      "********************\n",
      "Prompt: Write a post in r/tifu with the title: TIFU by cheating on my wife with a fictional woman\n",
      " System: You are a redditor.\n",
      "********************\n",
      "Prompt: Write a post in r/FML with the title: Today, I ascended\n",
      " System: You are a redditor.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: The Dark Knight (2008)\n",
      " System: You are a casual moviegoer with no experience in creative writing who occasionally writes IMDB reviews while waiting for food to cook in the microwave.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Mieza (Macedonia)\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Indiana Jones and the Temple of Doom (1984)\n",
      " System: You are a casual moviegoer with no experience in creative writing who occasionally writes IMDB reviews while waiting for food to cook in the microwave.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Gravity (2013)\n",
      " System: You are an overworked freelance graphic designer who watches movies to unwind, and you enjoy leaving the occasional IMDB review. It's a hobby that you find rewarding, and doesn't take much time or effort.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Predator (1987)\n",
      " System: You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\n",
      "********************\n",
      "Prompt: Write an IMDB review for the following movie: Any Which Way You Can (1980)\n",
      " System: You are an overworked freelance graphic designer who watches movies to unwind, and you enjoy leaving the occasional IMDB review. It's a hobby that you find rewarding, and doesn't take much time or effort.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Chronological dating\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write a post in r/TrueOffMyChest with the title: There is no ‘labor shortage’. The issue is caused by companies not willing to pay current market price for human talent.\n",
      " System: You are a redditor.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Choral poetry\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Cradle of civilization\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write a post in r/dating_advice with the title: Please stop immediately asking for my Snapchat\n",
      " System: You are a redditor.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Lamarckism\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n",
      "Prompt: Write the introductory section to a Wikipedia page with the following title: Hong Kong International Airport\n",
      " System: You are a wikipedia contributor.\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for idx, row in AI_train.sample(24, random_state=623).iterrows():\n",
    "  print(f\"Prompt: {row['prompt']}\\n System: {row['system']}\")\n",
    "  print('*'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMaXSglieulR"
   },
   "source": [
    "We can see that the GPT models were prompted to specifically imitate the creators of the human texts. There is a diverse range of writing styles, which will allow the AI detection model to learn deep patterns underlying GPT's text generation mechanism and allow it to generalise to unseen writing.\n",
    "\n",
    "## Tokenizing the training data\n",
    "\n",
    "The next step is to tokenize the data. We need to ensure that the text does not exceed the length of the model's max length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "8f6d6007ed2045c894ee907a694d4c8f",
      "922f9cc65002478ba1be69cc51f0bb34",
      "e0826549c2c44dbe89dbfda0a7b9678d",
      "957fd132fb6d4081b19745117e319882",
      "fa42d2dee7874ac4b81440653c5e1bca",
      "ce220a1cda594a4098c0f050bd3210b5",
      "1be64af06e144800a10c66fc524f18c6",
      "20bc8b3f394844dcab00a2e932d00c46",
      "ed5e1513c9b146e3b05683a39168c5d4",
      "715e0cf942484729a86ed5728669dd1c",
      "2d722c2cf6dd4c2d9cfc9fd9243dd3f3",
      "46dbd27efe7f4d84ab7dfe7a16ddce2e",
      "d5635f2a7efb4c14bbfbfad6bd76de54",
      "c77de461c7e5493d8bdd50c9a17017a3",
      "94f4a1bcd1934d74adcf7182514759f0",
      "8d4bf4cc611441c7b3f3f926a34d76d9",
      "125938e47ff040a6b17b9bb6c9ed87fd",
      "509a6abe86a64ad6b6b775ba6128944a",
      "7732c5e52dfe4109bcb51a582d7decb6",
      "d72aa02740d74e9a932bf7bb7991cbe0",
      "3fb022c93f4a4227a5c760b118fc880b",
      "24969d797e3c45cc9f26ce65d16cc8b3",
      "11e6d52701074e34b84bee286201b043",
      "5b1f69eb900248318e6a3c3f09579bad",
      "7492a54ac27047a5935d13e1e194a1af",
      "4eea683e8a4f46a58d8e7ef9c30d99f3",
      "c13a60959ce04cb98de0cfd64ca237ac",
      "567a9e2200324ddf821b06d4702d0e0d",
      "c51871220c9e44ceb1ec7e0236d861a4",
      "376996b2266b4515be28cdd4b7f88992",
      "81c1779a54ec48578c656cd15c8cb08a",
      "3f3f76f69d5c4642b1632b93bcd5722f",
      "4c535c0f386f466d8883801202cc9f6c",
      "4c6855bfa3a242ac86ffdae3787b4b24",
      "871ccca4ce0e4346ad9bf935e7870139",
      "4f8dc47d593e454b9203b65d934f2349",
      "338bada8dfb3457a9bde9a9a2682e244",
      "cebb4521af504cfdb1c05319757411e4",
      "fa82a9ca7d884470ad235699e0e4121e",
      "2a532fa584de44128e062c5cae464ba5",
      "6a22f225aa9647a59054ff6b015e5148",
      "b640368eef884d7191ff08ea66071f1a",
      "a6c0b60424b0463aa3b6e2a670ffa534",
      "ecbda2ba85c64783aec003722284606f"
     ]
    },
    "id": "m8mmgeANhQRz",
    "outputId": "3eb0ed20-7fbe-44a5-860c-e8ad5e3675cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6d6007ed2045c894ee907a694d4c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46dbd27efe7f4d84ab7dfe7a16ddce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e6d52701074e34b84bee286201b043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6855bfa3a242ac86ffdae3787b4b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tb4XNTod9kLa",
    "outputId": "554d42c4-bb75-4035-b227-a10ecc4437cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yTPohNrhRaf",
    "outputId": "24dff90e-9b45-414a-cd4a-e30906d74aee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16381 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "AI_train['token_count'] = AI_train['text'].apply(lambda text: len(tokenizer(text)['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlHi19XQi4vQ"
   },
   "outputs": [],
   "source": [
    "human_train['token_count'] = human_train['text'].apply(lambda text: len(tokenizer(text)['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86MTjI_D9vVO"
   },
   "source": [
    "We see that some of the samples greatly exceed the max length allowed by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "PL0MkfJ3jMNB",
    "outputId": "094fd315-21ca-4af3-95b3-0091893fbb8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>335.167408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>163.435898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>315.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16381.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> float64</label>"
      ],
      "text/plain": [
       "count    25184.000000\n",
       "mean       335.167408\n",
       "std        163.435898\n",
       "min         78.000000\n",
       "25%        242.000000\n",
       "50%        315.000000\n",
       "75%        419.000000\n",
       "max      16381.000000\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_train['token_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "8Cg0MTayjPS0",
    "outputId": "e2f05fb2-6d5b-4d92-e0f1-9beb0b23fdae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"AI_train\",\n  \"rows\": 25184,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25184,\n        \"samples\": [\n          \"As a fan of the original Iron Man, I had high hopes for its sequel, Iron Man 2. While it had its moments and some standout performances, I couldn't shake the feeling that it fell short of its predecessor's charm.\\n\\nOne of the biggest strengths of Iron Man 2 is the cast. Robert Downey Jr. once again delivers a dazzling performance as Tony Stark, effortlessly blending charisma with vulnerability. The introduction of Scarlett Johansson as Natasha Romanoff (Black Widow) adds a layer of intrigue, although I wish they had explored her character more thoroughly. Don Cheadle, stepping in as Rhodey, does a solid job, too, but I felt there was a noticeable difference in chemistry when compared to his predecessor, Terrence Howard.\\n\\nThe plot centers around Tony's struggle with his identity as Iron Man, his battle against government pressure, and the looming threat posed by Ivan Vanko, played by Mickey Rourke. Vanko's motivations are somewhat muddled throughout the film, making it difficult to connect with him as an antagonist. While there are electrifying moments\\u2014such as the Monaco Grand Prix scene\\u2014the pacing feels off at times. It's as if the film is trying to juggle a few too many subplots, including Tony's declining health due to the Palladium in his chest and the introduction of new technology and rivals.\\n\\nVisually, Iron Man 2 delivers some stunning effects, and the action sequences are entertaining if a bit frenetic. However, for all the spectacle, I often found myself yearning for more depth in the storytelling. The film seemed to rely heavily on setting up future installments of the Marvel Cinematic Universe rather than standing strong on its own. While there are some humorous exchanges (Tony's quips are always welcome), the film lacks the emotional depth and stakes that really resonated in the first Iron Man.\\n\\nOverall, Iron Man 2 isn\\u2019t a bad movie\\u2014it has entertaining moments and impressive performances\\u2014but it feels like it's caught in a transitional phase, shuffling us from one big reveal to the next. If you're a fan of the MCU, it's definitely worth a watch, but you may find it doesn't quite capture the magic like the original. Here\\u2019s hoping the next chapter can balance more seamlessly the desire for character development and dynamic action.\",\n          \"The Titanomachy, often referred to as the War of the Titans, is a significant mythological conflict in ancient Greek mythology that depicts the struggle between the Olympian gods, led by Zeus, and the Titans, a powerful race of deities who preceded them. This epic battle, which symbolizes the transition of power from the older generation of gods to the younger, is a central theme in Greek mythological narratives and serves as a foundational story for the pantheon of deities worshipped in ancient Greece.\\n\\nAccording to various ancient sources, the Titanomachy lasted for ten years and culminated in the defeat of the Titans, who were subsequently imprisoned in Tartarus, a deep abyss used as a dungeon of torment. The conflict is characterized by grand battles, heroic deeds, and the involvement of various mythological creatures and allies, including the Cyclopes and the Hecatoncheires, who played crucial roles in assisting Zeus and his siblings. The Titanomachy not only illustrates the themes of struggle and succession within divine hierarchies but also reflects broader concepts of order versus chaos in the cosmos.\\n\\nThe narrative of the Titanomachy has been recounted in various literary works, including Hesiod's \\\"Theogony,\\\" and has influenced art, literature, and culture throughout history, making it a pivotal element of classical mythology and storytelling.\",\n          \"\\\"Sister Act\\\" (1992) is an absolute gem that blends comedy, music, and a touch of spirituality in a delightful package. Who knew that seeing Whoopi Goldberg clad in a habit would be one of the most entertaining things ever? From the moment Deloris Van Cartier finds herself hiding in a convent, the film combines zany humor with unexpected character growth, all set against the backdrop of toe-tapping musical numbers.\\n\\nGoldberg is a powerhouse, embodying the flamboyant Las Vegas performer forced to adapt to a life of piousness with laughter and resilience. The supporting cast\\u2014especially the nuns, played superbly by Kathy Najimy and Wendy Makkena\\u2014bring warmth and charisma to the story. The chemistry among the cast enhances the overall experience, reminding us that when life sends you for a surprise retreat in a convent, you can sing about it!\\n\\nThe film's message of embracing diverse backgrounds and dispelling stereotypes really shines through. It's both funny and heartwarming, and the uplifting musical numbers\\u2014particularly the stunning renditions of classic songs\\u2014are impossible not to hum along to. \\n\\nWhile some plot points feel convenient and predictable, \\u201cSister Act\\u201d holds up beautifully as a feel-good film that explores themes of friendship, self-discovery, and faith through humor. Perfect for a cozy movie night or when you need a smile after a long week. \\n\\nIn a world where everything feels a bit too serious at times, \\u201cSister Act\\u201d reminds us that laughter and love can be found in the unlikeliest of places! If you haven\\u2019t seen it\\u2014or it\\u2019s been a while\\u2014grab some popcorn and immerse yourself in this charmer. You won\\u2019t regret it!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16450,\n        \"samples\": [\n          \"Write the introductory section to a Wikipedia page with the following title: Washington at Princeton\",\n          \"Write the introductory section to a Wikipedia page with the following title: 1988 World Series\",\n          \"Write a post in r/AmItheAsshole with the title: UPDATE AITA for not sharing my medical history before being pranked?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"system\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"You are a wikipedia contributor.\",\n          \"You are a redditor.\",\n          \"You are a casual moviegoer with no experience in creative writing, leaving an IMDB review for the first time.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"gpt-4o\",\n          \"gpt-4o-mini\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3583877522265999,\n        \"min\": 0.0,\n        \"max\": 1.2,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          0.03,\n          0.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Removed headers, replaced \\\"a graphic designer\\\" with \\\"a web developer\\\"\",\n          \"Removed headers, replaced \\\"overworked freelance graphic designer\\\" with \\\"nurse\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 163,\n        \"min\": 78,\n        \"max\": 16381,\n        \"num_unique_values\": 622,\n        \"samples\": [\n          485,\n          335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-efbe9d8b-e3cb-4e36-a6dc-e24534554b83\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>system</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cleaning</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Metacritic is a review aggregation website tha...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19486</th>\n",
       "      <td>So, here's the situation. I (26M) have a half-...</td>\n",
       "      <td>Write a post in r/AmItheAsshole with the title...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.19</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21694</th>\n",
       "      <td>Obligatory, this didn't happen today, but rath...</td>\n",
       "      <td>Write a post in r/tifu with the title: TIFU by...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.18</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>5146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21676</th>\n",
       "      <td>So, fellow Redditors, grab your popcorn becaus...</td>\n",
       "      <td>Write a post in r/tifu with the title: TIFU by...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.07</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21654</th>\n",
       "      <td>So, I (26M) have dabbled in some psychedelics ...</td>\n",
       "      <td>Write a post in r/tifu with the title: TIFU us...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.18</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>Today, I was at a crucial point during an impo...</td>\n",
       "      <td>Write a post in r/FML with the title: I coughe...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>Post: FML. Just found out there's a new lockdo...</td>\n",
       "      <td>Write a post in r/FML with the title: New lock...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.17</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23832</th>\n",
       "      <td>I'm so sorry to hear that you're going through...</td>\n",
       "      <td>Write a post in r/parenting with the title: My...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.16</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23543</th>\n",
       "      <td>Today, I found out that my younger sister, who...</td>\n",
       "      <td>Write a post in r/FML with the title: She's bu...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.19</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23096</th>\n",
       "      <td>I'm really glad you're still here with us to s...</td>\n",
       "      <td>Write a post in r/confessions with the title: ...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.17</td>\n",
       "      <td>Removed headers</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25184 rows × 7 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efbe9d8b-e3cb-4e36-a6dc-e24534554b83')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-efbe9d8b-e3cb-4e36-a6dc-e24534554b83 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-efbe9d8b-e3cb-4e36-a6dc-e24534554b83');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-33df8c43-25cc-4a65-8cad-befd6e2e971b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33df8c43-25cc-4a65-8cad-befd6e2e971b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-33df8c43-25cc-4a65-8cad-befd6e2e971b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "415    Metacritic is a review aggregation website tha...   \n",
       "19486  So, here's the situation. I (26M) have a half-...   \n",
       "21694  Obligatory, this didn't happen today, but rath...   \n",
       "21676  So, fellow Redditors, grab your popcorn becaus...   \n",
       "21654  So, I (26M) have dabbled in some psychedelics ...   \n",
       "...                                                  ...   \n",
       "23499  Today, I was at a crucial point during an impo...   \n",
       "23565  Post: FML. Just found out there's a new lockdo...   \n",
       "23832  I'm so sorry to hear that you're going through...   \n",
       "23543  Today, I found out that my younger sister, who...   \n",
       "23096  I'm really glad you're still here with us to s...   \n",
       "\n",
       "                                                  prompt  \\\n",
       "415    Write the introductory section to a Wikipedia ...   \n",
       "19486  Write a post in r/AmItheAsshole with the title...   \n",
       "21694  Write a post in r/tifu with the title: TIFU by...   \n",
       "21676  Write a post in r/tifu with the title: TIFU by...   \n",
       "21654  Write a post in r/tifu with the title: TIFU us...   \n",
       "...                                                  ...   \n",
       "23499  Write a post in r/FML with the title: I coughe...   \n",
       "23565  Write a post in r/FML with the title: New lock...   \n",
       "23832  Write a post in r/parenting with the title: My...   \n",
       "23543  Write a post in r/FML with the title: She's bu...   \n",
       "23096  Write a post in r/confessions with the title: ...   \n",
       "\n",
       "                                 system        model  temperature  \\\n",
       "415    You are a wikipedia contributor.  gpt-4o-mini         0.41   \n",
       "19486               You are a redditor.       gpt-4o         1.19   \n",
       "21694               You are a redditor.       gpt-4o         1.18   \n",
       "21676               You are a redditor.  gpt-4o-mini         1.07   \n",
       "21654               You are a redditor.  gpt-4o-mini         1.18   \n",
       "...                                 ...          ...          ...   \n",
       "23499               You are a redditor.       gpt-4o         1.03   \n",
       "23565               You are a redditor.       gpt-4o         1.17   \n",
       "23832               You are a redditor.  gpt-4o-mini         1.16   \n",
       "23543               You are a redditor.       gpt-4o         1.19   \n",
       "23096               You are a redditor.       gpt-4o         1.17   \n",
       "\n",
       "                                      cleaning  token_count  \n",
       "415    Removed headers and markdown formatting        16381  \n",
       "19486                          Removed headers         6670  \n",
       "21694                          Removed headers         5146  \n",
       "21676                          Removed headers          868  \n",
       "21654                          Removed headers          846  \n",
       "...                                        ...          ...  \n",
       "23499                          Removed headers           89  \n",
       "23565                          Removed headers           83  \n",
       "23832                          Removed headers           82  \n",
       "23543                          Removed headers           81  \n",
       "23096                          Removed headers           78  \n",
       "\n",
       "[25184 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_train.sort_values(by='token_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "BZ4csDGljXfx",
    "outputId": "c4e0098c-2afb-4004-8f9e-f3a8b66c4804"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"human_train\",\n  \"rows\": 25180,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25180,\n        \"samples\": [\n          \"Throwaway. Long time lurker, first time posting. \\n\\nI am the oldest daughter of 4 children. I\\u2019m currently 25, 2nd oldest is 23, 3rd is 20, and youngest is 18. \\n\\nWhen I was 8 years old, my mom had an affair with a family friend. I, being the oldest has remembered most of it and my younger siblings only remember growing up with our parents co parenting. \\n\\nThis has put a strain on my mothers and I\\u2019s relationship- she cheated on my father who was battling cancer. \\nShe didn\\u2019t even try to keep it a secret from the kids, I remember during family/friend gatherings when everyone would be inside and I\\u2019d see my mom and the family friend kissing or doing things in the pool. As a kid I didn\\u2019t understand, but as I got older I realized what she was doing in front of us and I feel sick. \\n\\nPeople ended up catching on to their affair years later, and my mom left my dad and started a new relationship with this \\u201cfamily friend\\u201d. They split up shortly after that because he cheated on my mother. \\n\\nI\\u2019ve confronted her about this after my dad passed and we all went to see a family therapist. This was roughly 3 years ago. \\n\\nMy mom has since remarried to an incredible man, but recently she was out and bumped in to this man from her past. They exchanged emails and she confided in me that they have been sending emails back and forth and are planning to meet up to chat and catch up. I read the messages and it\\u2019s very apparent that the guy still has feelings, while my mom is trying to make it seem like she\\u2019s just catching up with an old Co worker. But I know my mother, and I know she is still slightly infatuated with this man, and flattered that he still wants her. I mean it\\u2019s been years, why else would you want to catch up?\\n\\nMy new step dad knows about her past, and while he doesn\\u2019t agree with it, it\\u2019s been years, he wasn\\u2019t in her life yet.\\n\\nShe asked me what I thought about her meeting up with him, and said something along the lines of needing closure. She asked for my honest opinion about the matter and I told her; \\n\\n\\u201cTo be honest mom, you dealing with this guy in the past ruined yours and daddy\\u2019s marriage and you guys had 4 kids. Idk why you think it wouldn\\u2019t ruin this one, but why don\\u2019t you stop being a whore and stop thinking with your pussy, and delete this guys damn email?\\u201d\\n\\nShe cried, said she couldn\\u2019t believe I just called her a whore and left my house. We haven\\u2019t spoken for a few days.\\n\\nToday, I got a call from my siblings saying I hurt my moms feelings and whatever happened betweens her and daddy\\u2019s marriage was between them. I disagree, I had to witness my mom cheating on my father, I watched him die in bed while she was off to god knows where with this man. She asked for my opinion and my opinion is that she\\u2019s selfish and a whore who left my dad to die on his own and she wants to rekindle with this man and possibly cheat on my new step dad? Sorry I\\u2019m not sorry for feeling some type of way about it.\",\n          \"Ko to tamo peva is the best comedy of all times. Believe me i saw a lot of movies and comedies but tell me which one make you smile every time you watching it. But truth is that the humour in this comedy is special.It is caratherisic for serbia. And all former republic of yugoslavia know it very well!!! So i think the rest of audience (for example: In Europe)can't enjoy it so much. Because the subtitles ruin the hole thing. But they should at least try!!!! Yes it is ironic! This is the best flick in Serbian history and the world doesn't understand it! :-) If you have got a chance to see this one, don't blew up OK!\",\n          \"I had a boss who was a real turd. He labored under the delusion he was an excellent boss and couldn\\u2019t put together that his behavior and the crappy pay was why he had such a hard time keeping employees. He also thought it was acceptable to call his female employees hun, sweetie, and sugar. He was a condescending asswipe who consistently passed over more qualified women for promotions in favor of promoting less qualified men. I had to stay until I could find a better job because I enjoy eating, and couldn\\u2019t afford to leave unless I had something else. I got an interview with a competitor who hired me on making more than I made with him. \\n\\nI turned in my two weeks and he said \\u201coh sweetie, you know you can\\u2019t leave.\\u201d I said I absolutely am leaving. He got the smuggest look on his face and said \\u201cWell, I\\u2019m not accepting this, sugar. Guess you\\u2019re here to stay.\\u201d I got so furious and decided that was it. I said \\u201cwell screw this then, I quit. Effective immediately.\\u201d Called my new job, explained what happened in front of him as he sat there slack jawed and agreed start the next day. I packed my stuff and left. \\n\\nA former coworker said it was an asshole thing for me to just up and quit on the spot, but if he refused to accept the resignation he could easily have tried to screw me over when my last day did come. My new boss says he deserved it and I\\u2019m not the asshole for quitting like I did. My boyfriend says he can see how other employees might feel like I was an asshole by making them cover my absence, but sees how I\\u2019m not the asshole for walking out of that toxic environment. So just because I\\u2019m curious, I thought I\\u2019d ask here. AITA?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"Reddit (r/AmItheAsshole)\",\n          \"Reddit (r/inlaws)\",\n          \"Reddit (r/confessions)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 18,\n        \"max\": 4463,\n        \"num_unique_values\": 1494,\n        \"samples\": [\n          574,\n          623,\n          184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-caf17b3a-c3f3-4fe1-a94e-202e23f45181\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22797</th>\n",
       "      <td>Okay, fair warning, this one is long as hell. ...</td>\n",
       "      <td>Reddit (r/confessions)</td>\n",
       "      <td>4463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21670</th>\n",
       "      <td>Obligatory this happened 9 years ago but I sti...</td>\n",
       "      <td>Reddit (r/tifu)</td>\n",
       "      <td>4371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22882</th>\n",
       "      <td>Some years ago I decided to go alone on a beau...</td>\n",
       "      <td>Reddit (r/confessions)</td>\n",
       "      <td>4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20252</th>\n",
       "      <td>[Original Post](https://www.reddit.com/r/relat...</td>\n",
       "      <td>Reddit (r/relationship_advice)</td>\n",
       "      <td>4205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22957</th>\n",
       "      <td>Disclaimer: his vaccine injury has been confir...</td>\n",
       "      <td>Reddit (r/confessions)</td>\n",
       "      <td>4189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>A great film in its genre, the direction, acti...</td>\n",
       "      <td>IMDB review</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12475</th>\n",
       "      <td>Great movie - especially the music - Etta Jame...</td>\n",
       "      <td>IMDB review</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16757</th>\n",
       "      <td>One of the funniest movies made in recent year...</td>\n",
       "      <td>IMDB review</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>You'd better choose Paul Verhoeven's even if y...</td>\n",
       "      <td>IMDB review</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17083</th>\n",
       "      <td>This is a great movie. Too bad it is not avail...</td>\n",
       "      <td>IMDB review</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25180 rows × 3 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caf17b3a-c3f3-4fe1-a94e-202e23f45181')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-caf17b3a-c3f3-4fe1-a94e-202e23f45181 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-caf17b3a-c3f3-4fe1-a94e-202e23f45181');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c2196996-4b75-4e40-ba6d-47a34dc936f9\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2196996-4b75-4e40-ba6d-47a34dc936f9')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c2196996-4b75-4e40-ba6d-47a34dc936f9 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "22797  Okay, fair warning, this one is long as hell. ...   \n",
       "21670  Obligatory this happened 9 years ago but I sti...   \n",
       "22882  Some years ago I decided to go alone on a beau...   \n",
       "20252  [Original Post](https://www.reddit.com/r/relat...   \n",
       "22957  Disclaimer: his vaccine injury has been confir...   \n",
       "...                                                  ...   \n",
       "15652  A great film in its genre, the direction, acti...   \n",
       "12475  Great movie - especially the music - Etta Jame...   \n",
       "16757  One of the funniest movies made in recent year...   \n",
       "9720   You'd better choose Paul Verhoeven's even if y...   \n",
       "17083  This is a great movie. Too bad it is not avail...   \n",
       "\n",
       "                               source  token_count  \n",
       "22797          Reddit (r/confessions)         4463  \n",
       "21670                 Reddit (r/tifu)         4371  \n",
       "22882          Reddit (r/confessions)         4337  \n",
       "20252  Reddit (r/relationship_advice)         4205  \n",
       "22957          Reddit (r/confessions)         4189  \n",
       "...                               ...          ...  \n",
       "15652                     IMDB review           31  \n",
       "12475                     IMDB review           30  \n",
       "16757                     IMDB review           26  \n",
       "9720                      IMDB review           21  \n",
       "17083                     IMDB review           18  \n",
       "\n",
       "[25180 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_train.sort_values(by='token_count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WfpuhB694jr"
   },
   "source": [
    "We will need to preprocess the training data so that the model does not receive input that exceeds the max sequence length. While the tokenizer allows for input to be truncated, this would result in the model getting some samples that are cut off mid-sentence. Instead of this, I'll use a strategy where the text is chunked into paragraphs, and in case the input is too long, it gets truncated to the the leading paragraphs, not the leading tokens.\n",
    "\n",
    "Since DistilBERT does not recognise a paragraph delimiter as a token, I'll add it to the vocabulary. This would provide the model insight into the paragraph structure of the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjaRxlAh-o--",
    "outputId": "295c1fb8-5538-4921-af75-1ba01943262f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8667, 106, 8667, 106, 102]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Hello! Hello!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SooWi8ny-sV_",
    "outputId": "174ed5db-042f-42f8-c01c-2428aa9d4189"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8667, 106, 8667, 106, 102]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Hello!\\n\\nHello!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbvhMH9FrKfE",
    "outputId": "a0868e08-4583-4c10-9779-dfcc774a7daf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(['\\n\\n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HkCcAJj-wG8"
   },
   "source": [
    "Next, we will define a function that takes a list of tokenized \"chunks\", combines as many chunks as will fit into the model, and then pads to the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDaIlRCBjjp8"
   },
   "outputs": [],
   "source": [
    "def truncator(group_encodings):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    input_ids = [tokenizer.cls_token_id]\n",
    "    attention_mask = [1]\n",
    "    n = 0\n",
    "    while n < len(group_encodings):\n",
    "        if len(input_ids) + len(group_encodings[n]['input_ids']) + 1 >= tokenizer.model_max_length:\n",
    "            break\n",
    "        input_ids = [*input_ids, *group_encodings[n]['input_ids']]\n",
    "        attention_mask = [*attention_mask, *group_encodings[n]['attention_mask']]\n",
    "        n += 1\n",
    "\n",
    "    input_ids.append(tokenizer.sep_token_id)\n",
    "    attention_mask.append(1)\n",
    "\n",
    "    pad_length = tokenizer.model_max_length - len(input_ids)\n",
    "    input_ids = [*input_ids, *[tokenizer.pad_token_id]*pad_length]\n",
    "    attention_mask = [*attention_mask, *[0]*pad_length]\n",
    "\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask}, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTz-3ofe_wJ5"
   },
   "source": [
    "Let's look at an example text that's too long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "gJuSTVx2nSpl",
    "outputId": "362aa4ae-509f-43f9-9328-690b6af38366"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Stuttgart (German: [ˈʃtʊtɡaʁt] ; Swabian: Schduagert [ˈʒ̊d̥ua̯ɡ̊ɛʕd̥]; names in other languages) is the capital and largest city of the German state of Baden-Württemberg. It is located on the Neckar river in a fertile valley known as the Stuttgarter Kessel (Stuttgart Cauldron) and lies an hour from the Swabian Jura and the Black Forest. Stuttgart has a population of 632,865 as of 2022, making it the sixth largest city in Germany, while over 2.8 million people live in the city\\'s administrative region and nearly 5.5 million people in its metropolitan area, making it the fourth largest metropolitan area in Germany. The city and metropolitan area are consistently ranked among the top 5 European metropolitan areas by GDP; Mercer listed Stuttgart as 21st on its 2015 list of cities by quality of living; innovation agency 2thinknow ranked the city 24th globally out of 442 cities in its Innovation Cities Index; and the Globalization and World Cities Research Network ranked the city as a Beta-status global city in their 2020 survey. Stuttgart was one of the host cities for the official tournaments of the 1974 and 2006 FIFA World Cups.\\n\\nStuttgart is unusual in the scheme of German cities. It is spread across a variety of hills (some of them covered in vineyards), valleys (especially around the Neckar river and the Stuttgart basin) and parks. The city is known as the \"cradle of the automobile\". As such, it is home to famous automobile museums like the Mercedes-Benz Museum and Porsche Museum, as well as numerous auto-enthusiast magazines, which contributes to Stuttgart\\'s status as Germany\\'s \"Autohauptstadt\" (\"car capital city\"/\"capital of cars\"). The city\\'s tourism slogan is \"Stuttgart offers more\". Under current plans to improve transport links to the international infrastructure (as part of the Stuttgart 21 project), Stuttgart unveiled a new city logo and slogan in March 2008, describing itself as \"Das neue Herz Europas\" (\"The new Heart of Europe\"). For business, it describes itself as \"Where business meets the future\". In July 2010, the city unveiled a new logo, designed to entice more business people to stay in the city and enjoy breaks in the area.\\n\\nSince the seventh millennium BC, the Stuttgart area has been an important agricultural area and has been host to a number of cultures seeking to utilize the rich soil of the Neckar valley. The Roman Empire conquered the area in AD 83 and built a massive castrum near Bad Cannstatt, making it the most important regional centre for several centuries. Stuttgart\\'s roots were truly laid in the tenth century with its founding by Liudolf, Duke of Swabia, as a stud farm for his warhorses. Initially overshadowed by nearby Bad Cannstatt, the town grew steadily and was granted a charter in 1320. The fortunes of Stuttgart turned with those of the House of Württemberg, and they made it the capital of their county, duchy, and kingdom from the 15th century to 1918. Stuttgart prospered despite setbacks in the Thirty Years\\' War and devastating air raids by the Allies on the city and its automobile production during World War II. However, by 1952, the city had bounced back and became the major cultural, economic, industrial, financial, tourism and publishing centre it is today.\\n\\nStuttgart is known for its strong high-tech industry, especially in the automotive sector. It has the highest general standard of prosperity of any German city. In addition to many medium-sized companies, several major corporations are headquartered in Stuttgart, including Porsche, Bosch, Exyte, and Mercedes-Benz Group. Stuttgart is an important financial center; the Stuttgart Stock Exchange is the second largest in Germany (after Frankfurt), and the Landesbank Baden-Württemberg (LBBW) is Germany\\'s largest Landesbank. Stuttgart is also a major transport junction; it is among the most congested conurbations of Europe, and its airport is the sixth-busiest in Germany (2019). Stuttgart is a city with a high number of immigrants; according to Dorling Kindersley\\'s Eyewitness Travel Guide to Germany, \"In the city of Stuttgart, every third inhabitant is a foreigner.\" 40% of Stuttgart\\'s residents, and 64% of the population below the age of five, are of immigrant background. In the rest of Germany, 28.7% of people are of immigrant background, with a relatively higher percentage living in cities and former western Germany (such as Stuttgart).'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = human_train[human_train['token_count'] > tokenizer.model_max_length].sample(1, random_state=623).iloc[0]['text']\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjENYjrj_Kcg"
   },
   "source": [
    "If we divide the text into paragraphs, we need to also account for the possibility that the first paragraph also exceeds the model max length. We can introduce a hierarchy of delimiters: we first split the text into paragraphs, and if the first paragraph is too long, we'll split that into lines, in case the line delimiter ('\\n') is used. If the first line is too long, we'll split that into sentences, and if the first sentence is still too long, *then* we'll simpy truncate. We'll do this process using regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiCqwNNO_pCp"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "PARAGRAPH_SEP_PATTERN = regex.compile(r'(?<=\\n\\n)')\n",
    "LINE_SEP_PATTERN = regex.compile('[\\n]+')\n",
    "PUNCT_PATTERN = regex.compile(r'(?<=[\\p{P}])(?=\\s+)')\n",
    "\n",
    "def tokenizer_custom_truncation(text):\n",
    "  # split text into paragraphs and tokenize\n",
    "    paragraphs = PARAGRAPH_SEP_PATTERN.split(text)\n",
    "    paragraph_encodings = [tokenizer(para, add_special_tokens=False) for para in paragraphs]\n",
    "\n",
    "  # if first paragraph is too long, further split text into lines and tokenize\n",
    "    if len(paragraph_encodings[0]['input_ids']) +2 >= tokenizer.model_max_length:\n",
    "        lines = LINE_SEP_PATTERN.split(paragraphs[0])\n",
    "        line_encodings = [tokenizer(line, add_special_tokens=False) for line in lines]\n",
    "\n",
    "      # if first line is still too long, split first line on punctuation and tokenize\n",
    "        if len(line_encodings[0]['input_ids']) +2 >= tokenizer.model_max_length:\n",
    "            sentences = PUNCT_PATTERN.split(lines[0])\n",
    "            sentence_encodings = [tokenizer(sentence, add_special_tokens=False) for sentence in sentences]\n",
    "\n",
    "          # if first sentence is still too long, just return truncated first sentence\n",
    "            if len(sentence_encodings[0]['input_ids']) +2 >= tokenizer.model_max_length:\n",
    "              return tokenizer(sentences[0], truncation=True, padding='max_length')\n",
    "        # otherwise truncate first line split on sentences\n",
    "            else:\n",
    "              encodings, _ = truncator(sentence_encodings)\n",
    "              return encodings\n",
    "      # otherwise truncate first paragraph split on lines\n",
    "        else:\n",
    "            encodings, _ = truncator(line_encodings)\n",
    "            return encodings\n",
    "  # otherwise truncate whole text split on paragraphs\n",
    "    encodings, _ = truncator(paragraph_encodings)\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_6hH8WE_y1S"
   },
   "source": [
    "Let's see how the custom tokenizer processes our previous text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3VMUae3r5PR"
   },
   "outputs": [],
   "source": [
    "tokenized = tokenizer_custom_truncation(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99IfBMeGC9oO",
    "outputId": "b059aa10-e7e1-4468-89ed-0469b2623fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Stuttgart ( German : [ ˈʃtʊtɡaʁt ] ; Swabian : Schduagert [ [UNK] ] ; names in other languages ) is the capital and largest city of the German state of Baden - Württemberg. It is located on the Neckar river in a fertile valley known as the Stuttgarter Kessel ( Stuttgart Cauldron ) and lies an hour from the Swabian Jura and the Black Forest. Stuttgart has a population of 632, 865 as of 2022, making it the sixth largest city in Germany, while over 2. 8 million people live in the city ' s administrative region and nearly 5. 5 million people in its metropolitan area, making it the fourth largest metropolitan area in Germany. The city and metropolitan area are consistently ranked among the top 5 European metropolitan areas by GDP ; Mercer listed Stuttgart as 21st on its 2015 list of cities by quality of living ; innovation agency 2thinknow ranked the city 24th globally out of 442 cities in its Innovation Cities Index ; and the Globalization and World Cities Research Network ranked the city as a Beta - status global city in their 2020 survey. Stuttgart was one of the host cities for the official tournaments of the 1974 and 2006 FIFA World Cups. \n",
      "\n",
      " Stuttgart is unusual in the scheme of German cities. It is spread across a variety of hills ( some of them covered in vineyards ), valleys ( especially around the Neckar river and the Stuttgart basin ) and parks. The city is known as the \" cradle of the automobile \". As such, it is home to famous automobile museums like the Mercedes - Benz Museum and Porsche Museum, as well as numerous auto - enthusiast magazines, which contributes to Stuttgart ' s status as Germany ' s \" Autohauptstadt \" ( \" car capital city \" / \" capital of cars \" ). The city ' s tourism slogan is \" Stuttgart offers more \". Under current plans to improve transport links to the international infrastructure ( as part of the Stuttgart 21 project ), Stuttgart unveiled a new city logo and slogan in March 2008, describing itself as \" Das neue Herz Europas \" ( \" The new Heart of Europe \" ). For business, it describes itself as \" Where business meets the future \". In July 2010, the city unveiled a new logo, designed to entice more business people to stay in the city and enjoy breaks in the area. \n",
      "\n",
      " [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1oNd2uMDFZs"
   },
   "source": [
    "We've defined a custom tokenizer for a single text sample, but we also need to create a function that can tokenize a list of samples, since this is what we'll need to shape our input into a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1ZFacZH68rN"
   },
   "outputs": [],
   "source": [
    "def tokenize_list(texts):\n",
    "    encodings = [tokenizer_custom_truncation(text) for text in texts]\n",
    "    return {'input_ids': np.array([e['input_ids'] for e in encodings]),\n",
    "            'attention_mask': np.array([e['attention_mask'] for e in encodings])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNmtovqYEU41"
   },
   "source": [
    "We can now tokenize the data. We'll first label the human and AI training data and combine them into a single set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsJVa3LAEj8t"
   },
   "outputs": [],
   "source": [
    "AI_train['label'] = 1\n",
    "human_train['label'] = 0\n",
    "full_train = pd.concat([AI_train[['text','label']], human_train[['text','label']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHXe5zeaEmMp",
    "outputId": "55b97aa8-0b32-4899-a88a-72181b74937a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 1.07 s, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_train_encodings = tokenize_list(full_train['text'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEsB0xrHeulS"
   },
   "source": [
    "## Hyperparameter tuning using a validation set\n",
    "\n",
    "Before we can train a model, we need to determine the optimal number of epochs for training and learning rate schedule using a validation set. We'll need to first label the human and AI training data, then combine them into a single set before performing a train-validation split of the combined data. I'll use a random 80/20 split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:15.029380Z",
     "iopub.status.busy": "2025-04-12T05:22:15.029012Z",
     "iopub.status.idle": "2025-04-12T05:22:15.068301Z",
     "shell.execute_reply": "2025-04-12T05:22:15.066758Z",
     "shell.execute_reply.started": "2025-04-12T05:22:15.029345Z"
    },
    "id": "uYS9g47Kd-sm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_indices, val_indices = train_test_split(np.arange(len(full_train)), test_size=0.2, random_state=623, stratify=full_train['label'])\n",
    "\n",
    "train_encodings = {'input_ids': full_train_encodings['input_ids'][train_indices,:],\n",
    "                   'attention_mask': full_train_encodings['attention_mask'][train_indices,:]}\n",
    "val_encodings = {'input_ids': full_train_encodings['input_ids'][val_indices,:],\n",
    "                 'attention_mask': full_train_encodings['attention_mask'][val_indices,:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuHRDd6yeulS"
   },
   "source": [
    "Next, we convert the train and val encodings into a tensorflow dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:15.106647Z",
     "iopub.status.busy": "2025-04-12T05:22:15.106303Z",
     "iopub.status.idle": "2025-04-12T05:22:16.834964Z",
     "shell.execute_reply": "2025-04-12T05:22:16.833776Z",
     "shell.execute_reply.started": "2025-04-12T05:22:15.106623Z"
    },
    "id": "PBbFBPHDdBXX"
   },
   "outputs": [],
   "source": [
    "def create_dataset(encodings, labels, batch_size):\n",
    "    input_ids = tf.convert_to_tensor(encodings['input_ids'], dtype=tf.int32)\n",
    "    attention_mask = tf.convert_to_tensor(encodings['attention_mask'], dtype=tf.int32)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        ({\n",
    "          'input_ids': input_ids,\n",
    "          'attention_mask': attention_mask\n",
    "          }, labels)\n",
    "        ).shuffle(buffer_size=len(encodings['input_ids'])).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:22:16.836444Z",
     "iopub.status.busy": "2025-04-12T05:22:16.836154Z",
     "iopub.status.idle": "2025-04-12T05:23:03.301301Z",
     "shell.execute_reply": "2025-04-12T05:23:03.300207Z",
     "shell.execute_reply.started": "2025-04-12T05:22:16.836423Z"
    },
    "id": "F1XMfTRihRw0"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = create_dataset(train_encodings, full_train.iloc[train_indices]['label'].values, batch_size)\n",
    "val_dataset = create_dataset(val_encodings, full_train.iloc[val_indices]['label'].values, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzuXBsFSeulS"
   },
   "source": [
    "We are now ready to train the model. Because I'm running this notebook in Google Colab with a single GPU, the batch size needs to be small, and the number of batches will be high. I'll need to train with a low learning rate and monitor the validation metrics epoch by epoch. We'll begin at a learning rate of $1\\times 10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:24:21.434779Z",
     "iopub.status.busy": "2025-04-12T05:24:21.434321Z",
     "iopub.status.idle": "2025-04-12T05:24:21.443356Z",
     "shell.execute_reply": "2025-04-12T05:24:21.441778Z",
     "shell.execute_reply.started": "2025-04-12T05:24:21.434747Z"
    },
    "id": "5PpjSVv1iHLa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return learning_rate\n",
    "\n",
    "def get_compile_model():\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=2)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
    "                  metrics = ['accuracy'])\n",
    "    model.config.id2label = {0: 'human', 1: 'AI'}\n",
    "    return model\n",
    "\n",
    "def fit_model(model, train, val=None):\n",
    "    history = model.fit(train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[LearningRateScheduler(lr_scheduler)],\n",
    "                        validation_data=val,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "referenced_widgets": [
      "21df550b3aa8421d814654d31616edd2",
      "f2208b71af744c1596381d7e4b8e2c05",
      "f8fce2adc059497ca553583d1cb9920e",
      "1d89cc158e3b4606ab4c59d52735a99b",
      "ff27eef015664a148e0f7e6230351ae8",
      "e9a9ceb9e804480d9edacf0bdbd35e77",
      "a0ec3d0f50484a04a39254e877c2aa64",
      "4a1ecadd19644874b3c2787da1d79fef",
      "50d6c64c3cc747458d4a4fc351f9ee82",
      "8dc995857d1a4e3c8040ed50b4305680",
      "a7ff646e98954b0e9e88574fba784748"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:24:24.481870Z",
     "iopub.status.busy": "2025-04-12T05:24:24.480636Z",
     "iopub.status.idle": "2025-04-12T05:24:28.067294Z",
     "shell.execute_reply": "2025-04-12T05:24:28.066147Z",
     "shell.execute_reply.started": "2025-04-12T05:24:24.481831Z"
    },
    "id": "GMPr2DexiIRj",
    "outputId": "3e5965fb-37b3-44f2-fe28-5b77b80713f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21df550b3aa8421d814654d31616edd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "model_for_val = get_compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGdG-pPRiM7A",
    "outputId": "568d8a33-a0ea-4943-d10a-83f9e1869d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2611s 514ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 0.0412 - val_accuracy: 0.9891 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6aubLLveulT"
   },
   "source": [
    "After one epoch, the validation accuracy is already nearly 99%. We'll halve the learning rate and train for another epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iN-qAK7ZsIyB",
    "outputId": "67aa4b68-4113-4bcf-8cca-5735b5a80806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2595s 515ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0137 - val_accuracy: 0.9965 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCkoQ2t0eulT"
   },
   "source": [
    "We can see that both the train and validation loss have improved. We'll halve the learning rate and train for another epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wD9hae7A3hIi",
    "outputId": "94dae630-4d95-49ef-c7ff-2c11f81768a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2594s 515ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0132 - val_accuracy: 0.9968 - lr: 2.5000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the train and validation loss have continued to improve, we'll train again at half the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KmX9C7PTc71",
    "outputId": "82f84890-61ca-4e13-a2ab-9e4e39fe3162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2588s 514ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0162 - val_accuracy: 0.9959 - lr: 1.2500e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /=2\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjgAUluceulT"
   },
   "source": [
    "The training loss has improved, but the validation loss has become worse, indicating that the model is overfitting to the training data. We'll now train a new model on the full dataset with the same learning rate schedule. We'll save the model after each of the three cycles and evaluate each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4YbvAUoCFZU"
   },
   "source": [
    "## Training on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T05:24:43.459294Z",
     "iopub.status.busy": "2025-04-12T05:24:43.458854Z",
     "iopub.status.idle": "2025-04-12T05:24:46.016077Z",
     "shell.execute_reply": "2025-04-12T05:24:46.014813Z",
     "shell.execute_reply.started": "2025-04-12T05:24:43.459263Z"
    },
    "id": "Gtz8bkXjCG8x",
    "outputId": "f1d2b8f2-1dd8-4faa-852a-8f1db55babda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "model_full_train = get_compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:24:52.817048Z",
     "iopub.status.busy": "2025-04-12T05:24:52.815956Z",
     "iopub.status.idle": "2025-04-12T05:25:37.466616Z",
     "shell.execute_reply": "2025-04-12T05:25:37.464852Z",
     "shell.execute_reply.started": "2025-04-12T05:24:52.817008Z"
    },
    "id": "_uN_mOfkCPGj"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "full_train_dataset = create_dataset(full_train_encodings, full_train['label'].values, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5NUFQbFCY84",
    "outputId": "11f4d977-74c0-469a-e7a9-b778ed2a9dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6296/6296 [==============================] - 2992s 473ms/step - loss: 0.0407 - accuracy: 0.9849 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "fit_model(model_full_train, full_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYEJbJqhXUQq"
   },
   "outputs": [],
   "source": [
    "model_full_train.save_pretrained('model_epoch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIfVoXsgYp7-",
    "outputId": "6cccfae4-28a3-4f14-8981-f7b51e9a8312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2385s 473ms/step - loss: 0.0036 - accuracy: 0.9992 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_full_train, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TjPiLBxnVfg"
   },
   "outputs": [],
   "source": [
    "model_full_train.save_pretrained('model_epoch_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVxIy2r9m4L7",
    "outputId": "626d589f-e4c3-47cc-e171-7dcabe2dc160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2383s 473ms/step - loss: 0.0017 - accuracy: 0.9997 - lr: 2.5000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_full_train, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0FdNyLo1Gof"
   },
   "outputs": [],
   "source": [
    "model_full_train.save_pretrained('model_epoch_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5epWMDXPqYOh",
    "outputId": "288c471c-f340-4e27-b45e-d01a443cad3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5037/5037 [==============================] - 2383s 473ms/step - loss: 0.0012 - accuracy: 0.9998 - lr: 1.2500e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_full_train, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPQN2kaTqZKO"
   },
   "outputs": [],
   "source": [
    "model_full_train.save_pretrained('model_epoch_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckAcKHheHRFp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6969463,
     "sourceId": 11303907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11e6d52701074e34b84bee286201b043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b1f69eb900248318e6a3c3f09579bad",
       "IPY_MODEL_7492a54ac27047a5935d13e1e194a1af",
       "IPY_MODEL_4eea683e8a4f46a58d8e7ef9c30d99f3"
      ],
      "layout": "IPY_MODEL_c13a60959ce04cb98de0cfd64ca237ac"
     }
    },
    "125938e47ff040a6b17b9bb6c9ed87fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1be64af06e144800a10c66fc524f18c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d89cc158e3b4606ab4c59d52735a99b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8dc995857d1a4e3c8040ed50b4305680",
      "placeholder": "​",
      "style": "IPY_MODEL_a7ff646e98954b0e9e88574fba784748",
      "value": " 263M/263M [00:03&lt;00:00, 204MB/s]"
     }
    },
    "20bc8b3f394844dcab00a2e932d00c46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21df550b3aa8421d814654d31616edd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2208b71af744c1596381d7e4b8e2c05",
       "IPY_MODEL_f8fce2adc059497ca553583d1cb9920e",
       "IPY_MODEL_1d89cc158e3b4606ab4c59d52735a99b"
      ],
      "layout": "IPY_MODEL_ff27eef015664a148e0f7e6230351ae8"
     }
    },
    "24969d797e3c45cc9f26ce65d16cc8b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a532fa584de44128e062c5cae464ba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d722c2cf6dd4c2d9cfc9fd9243dd3f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "338bada8dfb3457a9bde9a9a2682e244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6c0b60424b0463aa3b6e2a670ffa534",
      "placeholder": "​",
      "style": "IPY_MODEL_ecbda2ba85c64783aec003722284606f",
      "value": " 465/465 [00:00&lt;00:00, 48.4kB/s]"
     }
    },
    "376996b2266b4515be28cdd4b7f88992": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f3f76f69d5c4642b1632b93bcd5722f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fb022c93f4a4227a5c760b118fc880b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46dbd27efe7f4d84ab7dfe7a16ddce2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5635f2a7efb4c14bbfbfad6bd76de54",
       "IPY_MODEL_c77de461c7e5493d8bdd50c9a17017a3",
       "IPY_MODEL_94f4a1bcd1934d74adcf7182514759f0"
      ],
      "layout": "IPY_MODEL_8d4bf4cc611441c7b3f3f926a34d76d9"
     }
    },
    "4a1ecadd19644874b3c2787da1d79fef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c535c0f386f466d8883801202cc9f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c6855bfa3a242ac86ffdae3787b4b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_871ccca4ce0e4346ad9bf935e7870139",
       "IPY_MODEL_4f8dc47d593e454b9203b65d934f2349",
       "IPY_MODEL_338bada8dfb3457a9bde9a9a2682e244"
      ],
      "layout": "IPY_MODEL_cebb4521af504cfdb1c05319757411e4"
     }
    },
    "4eea683e8a4f46a58d8e7ef9c30d99f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f3f76f69d5c4642b1632b93bcd5722f",
      "placeholder": "​",
      "style": "IPY_MODEL_4c535c0f386f466d8883801202cc9f6c",
      "value": " 436k/436k [00:00&lt;00:00, 3.29MB/s]"
     }
    },
    "4f8dc47d593e454b9203b65d934f2349": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a22f225aa9647a59054ff6b015e5148",
      "max": 465,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b640368eef884d7191ff08ea66071f1a",
      "value": 465
     }
    },
    "509a6abe86a64ad6b6b775ba6128944a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50d6c64c3cc747458d4a4fc351f9ee82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "567a9e2200324ddf821b06d4702d0e0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b1f69eb900248318e6a3c3f09579bad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_567a9e2200324ddf821b06d4702d0e0d",
      "placeholder": "​",
      "style": "IPY_MODEL_c51871220c9e44ceb1ec7e0236d861a4",
      "value": "tokenizer.json: 100%"
     }
    },
    "6a22f225aa9647a59054ff6b015e5148": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "715e0cf942484729a86ed5728669dd1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7492a54ac27047a5935d13e1e194a1af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_376996b2266b4515be28cdd4b7f88992",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81c1779a54ec48578c656cd15c8cb08a",
      "value": 435797
     }
    },
    "7732c5e52dfe4109bcb51a582d7decb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81c1779a54ec48578c656cd15c8cb08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "871ccca4ce0e4346ad9bf935e7870139": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa82a9ca7d884470ad235699e0e4121e",
      "placeholder": "​",
      "style": "IPY_MODEL_2a532fa584de44128e062c5cae464ba5",
      "value": "config.json: 100%"
     }
    },
    "8d4bf4cc611441c7b3f3f926a34d76d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dc995857d1a4e3c8040ed50b4305680": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f6d6007ed2045c894ee907a694d4c8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_922f9cc65002478ba1be69cc51f0bb34",
       "IPY_MODEL_e0826549c2c44dbe89dbfda0a7b9678d",
       "IPY_MODEL_957fd132fb6d4081b19745117e319882"
      ],
      "layout": "IPY_MODEL_fa42d2dee7874ac4b81440653c5e1bca"
     }
    },
    "922f9cc65002478ba1be69cc51f0bb34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce220a1cda594a4098c0f050bd3210b5",
      "placeholder": "​",
      "style": "IPY_MODEL_1be64af06e144800a10c66fc524f18c6",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "94f4a1bcd1934d74adcf7182514759f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fb022c93f4a4227a5c760b118fc880b",
      "placeholder": "​",
      "style": "IPY_MODEL_24969d797e3c45cc9f26ce65d16cc8b3",
      "value": " 213k/213k [00:00&lt;00:00, 1.70MB/s]"
     }
    },
    "957fd132fb6d4081b19745117e319882": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_715e0cf942484729a86ed5728669dd1c",
      "placeholder": "​",
      "style": "IPY_MODEL_2d722c2cf6dd4c2d9cfc9fd9243dd3f3",
      "value": " 49.0/49.0 [00:00&lt;00:00, 3.87kB/s]"
     }
    },
    "a0ec3d0f50484a04a39254e877c2aa64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6c0b60424b0463aa3b6e2a670ffa534": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7ff646e98954b0e9e88574fba784748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b640368eef884d7191ff08ea66071f1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c13a60959ce04cb98de0cfd64ca237ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c51871220c9e44ceb1ec7e0236d861a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c77de461c7e5493d8bdd50c9a17017a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7732c5e52dfe4109bcb51a582d7decb6",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d72aa02740d74e9a932bf7bb7991cbe0",
      "value": 213450
     }
    },
    "ce220a1cda594a4098c0f050bd3210b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cebb4521af504cfdb1c05319757411e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5635f2a7efb4c14bbfbfad6bd76de54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_125938e47ff040a6b17b9bb6c9ed87fd",
      "placeholder": "​",
      "style": "IPY_MODEL_509a6abe86a64ad6b6b775ba6128944a",
      "value": "vocab.txt: 100%"
     }
    },
    "d72aa02740d74e9a932bf7bb7991cbe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0826549c2c44dbe89dbfda0a7b9678d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20bc8b3f394844dcab00a2e932d00c46",
      "max": 49,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed5e1513c9b146e3b05683a39168c5d4",
      "value": 49
     }
    },
    "e9a9ceb9e804480d9edacf0bdbd35e77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecbda2ba85c64783aec003722284606f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed5e1513c9b146e3b05683a39168c5d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2208b71af744c1596381d7e4b8e2c05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9a9ceb9e804480d9edacf0bdbd35e77",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ec3d0f50484a04a39254e877c2aa64",
      "value": "model.safetensors: 100%"
     }
    },
    "f8fce2adc059497ca553583d1cb9920e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a1ecadd19644874b3c2787da1d79fef",
      "max": 263260784,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50d6c64c3cc747458d4a4fc351f9ee82",
      "value": 263260784
     }
    },
    "fa42d2dee7874ac4b81440653c5e1bca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa82a9ca7d884470ad235699e0e4121e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff27eef015664a148e0f7e6230351ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
