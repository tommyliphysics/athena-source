{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ff694d",
   "metadata": {
    "id": "51ff694d",
    "papermill": {
     "duration": 0.014184,
     "end_time": "2025-04-19T03:24:41.765696",
     "exception": false,
     "start_time": "2025-04-19T03:24:41.751512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building an AI-detector: fine-tuning DistilBERT with keras (GPT/Claude/Gemini)\n",
    "\n",
    "The model trained in the previous notebook on GPT data was able to identify gpt-4o and gpt-4o with high accuracy, but was less accurate on other models. In this notebook I'll build a new model that incorporates training data from Claude and Gemini, and also has a more complex, hierarchical structure: it consists of a base DistilBERT three-class classifier, to which a custom keras layer is attached which fuses the multiclass probabilities into a binary output layer.\n",
    "\n",
    "## Install and import dependencies\n",
    "\n",
    "First, we have to import the necessary libraries, making sure the latest version of the Huggingface \"transformers\" library is installed and is compatible with keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbaf437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:24:41.793065Z",
     "iopub.status.busy": "2025-04-19T03:24:41.792759Z",
     "iopub.status.idle": "2025-04-19T03:24:56.407192Z",
     "shell.execute_reply": "2025-04-19T03:24:56.406252Z"
    },
    "id": "1fbaf437",
    "outputId": "3cd5aa6c-8dde-45a4-d715-c3d98ab5488a",
    "papermill": {
     "duration": 14.629662,
     "end_time": "2025-04-19T03:24:56.408485",
     "exception": false,
     "start_time": "2025-04-19T03:24:41.778823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.51.1\r\n",
      "    Uninstalling transformers-4.51.1:\r\n",
      "      Successfully uninstalled transformers-4.51.1\r\n",
      "Successfully installed transformers-4.51.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491befb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:24:56.438633Z",
     "iopub.status.busy": "2025-04-19T03:24:56.438315Z",
     "iopub.status.idle": "2025-04-19T03:24:59.912492Z",
     "shell.execute_reply": "2025-04-19T03:24:59.911253Z"
    },
    "id": "491befb5",
    "outputId": "bb88af1d-c3e2-4cf6-dd3a-95ca243f9083",
    "papermill": {
     "duration": 3.491703,
     "end_time": "2025-04-19T03:24:59.914271",
     "exception": false,
     "start_time": "2025-04-19T03:24:56.422568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\r\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.1)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.5.0)\r\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (14.0.0)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b032a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:24:59.945740Z",
     "iopub.status.busy": "2025-04-19T03:24:59.945349Z",
     "iopub.status.idle": "2025-04-19T03:25:26.112009Z",
     "shell.execute_reply": "2025-04-19T03:25:26.111284Z"
    },
    "id": "c13b032a",
    "outputId": "270a7946-2429-43a9-c4d1-84e7bb12e184",
    "papermill": {
     "duration": 26.184208,
     "end_time": "2025-04-19T03:25:26.113483",
     "exception": false,
     "start_time": "2025-04-19T03:24:59.929275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 03:25:08.985280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745033109.230712      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745033109.300178      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26324d",
   "metadata": {
    "id": "8c26324d",
    "papermill": {
     "duration": 0.014015,
     "end_time": "2025-04-19T03:25:26.142393",
     "exception": false,
     "start_time": "2025-04-19T03:25:26.128378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the training data\n",
    "\n",
    "Next, we load and explore the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922a154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:26.173684Z",
     "iopub.status.busy": "2025-04-19T03:25:26.172500Z",
     "iopub.status.idle": "2025-04-19T03:25:29.371407Z",
     "shell.execute_reply": "2025-04-19T03:25:29.370659Z"
    },
    "id": "0922a154",
    "papermill": {
     "duration": 3.21553,
     "end_time": "2025-04-19T03:25:29.372938",
     "exception": false,
     "start_time": "2025-04-19T03:25:26.157408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "human_train = pd.read_csv('human_train.csv')\n",
    "AI_train = pd.read_csv('AI_train_gpt_claude_gemini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475863de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:29.402182Z",
     "iopub.status.busy": "2025-04-19T03:25:29.401556Z",
     "iopub.status.idle": "2025-04-19T03:25:29.428610Z",
     "shell.execute_reply": "2025-04-19T03:25:29.427741Z"
    },
    "id": "475863de",
    "outputId": "b38940db-e4b7-4b99-fb56-2ed749e6af35",
    "papermill": {
     "duration": 0.042711,
     "end_time": "2025-04-19T03:25:29.429844",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.387133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Mathison Turing (; 23 June 1912 – 7 June ...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Dewey Watson (born April 6, 1928) is an ...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry George Drickamer (November 19, 1918 – Ma...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony Stephen Fauci  ( FOW-chee; born Decemb...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles Hard Townes (July 28, 1915 – January 2...</td>\n",
       "      <td>English Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25175</th>\n",
       "      <td>I’ve been reading through AITA and found a pos...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>So, my mom bakes cakes and she got an order t...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25177</th>\n",
       "      <td>My brother is 16 and has Down Syndrome. For a ...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25178</th>\n",
       "      <td>With the news of Bill and Melinda Gates divorc...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25179</th>\n",
       "      <td>I love my girlfriend and I always have. We've ...</td>\n",
       "      <td>Reddit (r/OffMyChest)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25180 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Alan Mathison Turing (; 23 June 1912 – 7 June ...   \n",
       "1      James Dewey Watson (born April 6, 1928) is an ...   \n",
       "2      Harry George Drickamer (November 19, 1918 – Ma...   \n",
       "3      Anthony Stephen Fauci  ( FOW-chee; born Decemb...   \n",
       "4      Charles Hard Townes (July 28, 1915 – January 2...   \n",
       "...                                                  ...   \n",
       "25175  I’ve been reading through AITA and found a pos...   \n",
       "25176   So, my mom bakes cakes and she got an order t...   \n",
       "25177  My brother is 16 and has Down Syndrome. For a ...   \n",
       "25178  With the news of Bill and Melinda Gates divorc...   \n",
       "25179  I love my girlfriend and I always have. We've ...   \n",
       "\n",
       "                      source  \n",
       "0          English Wikipedia  \n",
       "1          English Wikipedia  \n",
       "2          English Wikipedia  \n",
       "3          English Wikipedia  \n",
       "4          English Wikipedia  \n",
       "...                      ...  \n",
       "25175  Reddit (r/OffMyChest)  \n",
       "25176  Reddit (r/OffMyChest)  \n",
       "25177  Reddit (r/OffMyChest)  \n",
       "25178  Reddit (r/OffMyChest)  \n",
       "25179  Reddit (r/OffMyChest)  \n",
       "\n",
       "[25180 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a20141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:29.458669Z",
     "iopub.status.busy": "2025-04-19T03:25:29.458388Z",
     "iopub.status.idle": "2025-04-19T03:25:29.472222Z",
     "shell.execute_reply": "2025-04-19T03:25:29.471367Z"
    },
    "id": "c5a20141",
    "outputId": "c0cb848b-0a6f-4925-b678-c79256f45ac5",
    "papermill": {
     "duration": 0.029038,
     "end_time": "2025-04-19T03:25:29.473421",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.444383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>system</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Turing (23 June 1912 – 7 June 1954) was a...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Dewey Watson (born April 6, 1920) is an ...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry George Drickamer (born [insert date of b...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony Stephen Fauci (born December 24, 1940)...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles H. Townes (July 28, 1915 – January 27,...</td>\n",
       "      <td>Write the introductory section to a Wikipedia ...</td>\n",
       "      <td>You are a wikipedia contributor.</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.03</td>\n",
       "      <td>Removed headers and markdown formatting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35249</th>\n",
       "      <td>Throwaway because my friends know my main. I (...</td>\n",
       "      <td>Write a post in r/relationship_advice with the...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>1.06</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35250</th>\n",
       "      <td>AITA for embarrassing my FIL after I repeatedl...</td>\n",
       "      <td>Write a post in r/AmItheAsshole with the title...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>1.09</td>\n",
       "      <td>Removed headers; removed \"So, \" at beginning o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35251</th>\n",
       "      <td>Look, I know it sucks to feel like you're talk...</td>\n",
       "      <td>Write a post in r/dating_advice with the title...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>1.17</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35252</th>\n",
       "      <td>AITA: For giving my deceased son's college fun...</td>\n",
       "      <td>Write a post in r/AmItheAsshole with the title...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Removed headers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35253</th>\n",
       "      <td>TIFU by Flashing My Boyfriend\\n\\nTs just happe...</td>\n",
       "      <td>Write a post in r/tifu with the title: TIFU by...</td>\n",
       "      <td>You are a redditor.</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>1.15</td>\n",
       "      <td>Removed headers; removed \"Okay, so\" at beginni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35254 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Alan Turing (23 June 1912 – 7 June 1954) was a...   \n",
       "1      James Dewey Watson (born April 6, 1920) is an ...   \n",
       "2      Harry George Drickamer (born [insert date of b...   \n",
       "3      Anthony Stephen Fauci (born December 24, 1940)...   \n",
       "4      Charles H. Townes (July 28, 1915 – January 27,...   \n",
       "...                                                  ...   \n",
       "35249  Throwaway because my friends know my main. I (...   \n",
       "35250  AITA for embarrassing my FIL after I repeatedl...   \n",
       "35251  Look, I know it sucks to feel like you're talk...   \n",
       "35252  AITA: For giving my deceased son's college fun...   \n",
       "35253  TIFU by Flashing My Boyfriend\\n\\nTs just happe...   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      Write the introductory section to a Wikipedia ...   \n",
       "1      Write the introductory section to a Wikipedia ...   \n",
       "2      Write the introductory section to a Wikipedia ...   \n",
       "3      Write the introductory section to a Wikipedia ...   \n",
       "4      Write the introductory section to a Wikipedia ...   \n",
       "...                                                  ...   \n",
       "35249  Write a post in r/relationship_advice with the...   \n",
       "35250  Write a post in r/AmItheAsshole with the title...   \n",
       "35251  Write a post in r/dating_advice with the title...   \n",
       "35252  Write a post in r/AmItheAsshole with the title...   \n",
       "35253  Write a post in r/tifu with the title: TIFU by...   \n",
       "\n",
       "                                 system             model  temperature  \\\n",
       "0      You are a wikipedia contributor.       gpt-4o-mini         0.22   \n",
       "1      You are a wikipedia contributor.       gpt-4o-mini         0.31   \n",
       "2      You are a wikipedia contributor.       gpt-4o-mini         0.54   \n",
       "3      You are a wikipedia contributor.       gpt-4o-mini         0.38   \n",
       "4      You are a wikipedia contributor.       gpt-4o-mini         0.03   \n",
       "...                                 ...               ...          ...   \n",
       "35249               You are a redditor.  gemini-2.0-flash         1.06   \n",
       "35250               You are a redditor.  gemini-1.5-flash         1.09   \n",
       "35251               You are a redditor.  gemini-2.0-flash         1.17   \n",
       "35252               You are a redditor.  gemini-1.5-flash         1.03   \n",
       "35253               You are a redditor.  gemini-2.0-flash         1.15   \n",
       "\n",
       "                                                cleaning  \n",
       "0                Removed headers and markdown formatting  \n",
       "1                Removed headers and markdown formatting  \n",
       "2                Removed headers and markdown formatting  \n",
       "3                Removed headers and markdown formatting  \n",
       "4                Removed headers and markdown formatting  \n",
       "...                                                  ...  \n",
       "35249                                    Removed headers  \n",
       "35250  Removed headers; removed \"So, \" at beginning o...  \n",
       "35251                                    Removed headers  \n",
       "35252                                    Removed headers  \n",
       "35253  Removed headers; removed \"Okay, so\" at beginni...  \n",
       "\n",
       "[35254 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb961a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:29.503269Z",
     "iopub.status.busy": "2025-04-19T03:25:29.502774Z",
     "iopub.status.idle": "2025-04-19T03:25:29.513561Z",
     "shell.execute_reply": "2025-04-19T03:25:29.512770Z"
    },
    "id": "1dbb961a",
    "outputId": "a262c0d3-685d-4848-8cd8-dbd49317c857",
    "papermill": {
     "duration": 0.027027,
     "end_time": "2025-04-19T03:25:29.514719",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.487692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gpt-4o-mini', 'gpt-4o', 'claude-3-5-haiku-20241022',\n",
       "       'claude-3-7-sonnet-20250219', 'gemini-2.0-flash',\n",
       "       'gemini-1.5-flash'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_train['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7b71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:29.543344Z",
     "iopub.status.busy": "2025-04-19T03:25:29.543046Z",
     "iopub.status.idle": "2025-04-19T03:25:29.599748Z",
     "shell.execute_reply": "2025-04-19T03:25:29.598875Z"
    },
    "id": "fba7b71a",
    "outputId": "8d43a1f2-e1c8-416a-bc2a-3c58778fd8b5",
    "papermill": {
     "duration": 0.072552,
     "end_time": "2025-04-19T03:25:29.601289",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.528737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-5-haiku-20241022</th>\n",
       "      <td>4532.0</td>\n",
       "      <td>0.550402</td>\n",
       "      <td>0.308040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-7-sonnet-20250219</th>\n",
       "      <td>503.0</td>\n",
       "      <td>0.549861</td>\n",
       "      <td>0.316231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-flash</th>\n",
       "      <td>1285.0</td>\n",
       "      <td>0.795922</td>\n",
       "      <td>0.357694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.0-flash</th>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.792899</td>\n",
       "      <td>0.357044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>2560.0</td>\n",
       "      <td>0.789266</td>\n",
       "      <td>0.361525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>22624.0</td>\n",
       "      <td>0.792187</td>\n",
       "      <td>0.358038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           temperature                                        \\\n",
       "                                 count      mean       std  min     25%  50%   \n",
       "model                                                                          \n",
       "claude-3-5-haiku-20241022       4532.0  0.550402  0.308040  0.0  0.2675  0.6   \n",
       "claude-3-7-sonnet-20250219       503.0  0.549861  0.316231  0.0  0.2600  0.6   \n",
       "gemini-1.5-flash                1285.0  0.795922  0.357694  0.0  0.5100  0.9   \n",
       "gemini-2.0-flash                3750.0  0.792899  0.357044  0.0  0.5200  0.9   \n",
       "gpt-4o                          2560.0  0.789266  0.361525  0.0  0.5100  0.9   \n",
       "gpt-4o-mini                    22624.0  0.792187  0.358038  0.0  0.5200  0.9   \n",
       "\n",
       "                                        \n",
       "                             75%   max  \n",
       "model                                   \n",
       "claude-3-5-haiku-20241022   0.82  0.99  \n",
       "claude-3-7-sonnet-20250219  0.84  0.99  \n",
       "gemini-1.5-flash            1.10  1.20  \n",
       "gemini-2.0-flash            1.10  1.20  \n",
       "gpt-4o                      1.10  1.20  \n",
       "gpt-4o-mini                 1.10  1.20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_train.groupby('model').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46760959",
   "metadata": {
    "id": "46760959",
    "papermill": {
     "duration": 0.014131,
     "end_time": "2025-04-19T03:25:29.629829",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.615698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our new dataset has 11,284 new AI samples generated by Claude-3.5-Haiku. Let's combine the AI and human data into a single training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851c2cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:29.659334Z",
     "iopub.status.busy": "2025-04-19T03:25:29.658559Z",
     "iopub.status.idle": "2025-04-19T03:25:29.670196Z",
     "shell.execute_reply": "2025-04-19T03:25:29.669409Z"
    },
    "id": "6851c2cc",
    "papermill": {
     "duration": 0.027985,
     "end_time": "2025-04-19T03:25:29.671578",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.643593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AI_train['label'] = 1\n",
    "human_train['label'] = 0\n",
    "full_train = pd.concat([human_train[['text','label']],AI_train[['text','label']]],\n",
    "                       ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d689a2",
   "metadata": {
    "id": "38d689a2",
    "papermill": {
     "duration": 0.014077,
     "end_time": "2025-04-19T03:25:29.700196",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.686119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39f907",
   "metadata": {
    "id": "7f39f907",
    "papermill": {
     "duration": 0.014871,
     "end_time": "2025-04-19T03:25:29.729271",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.714400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we have to tokenize our training corpus. As in the previous notebook, I will create a custom tokenizer that either truncates the input on paragraphs, lines, sentences or tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c74c8d",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "715191f75c6544cdbf73e0d825119688",
      "7362a53babfa4a65ac34c75aa23b2cdb",
      "3978b2540eef4deaa37540481f31b78f",
      "a48cba0ab1b94000848eb373e23b2336"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:29.822331Z",
     "iopub.status.busy": "2025-04-19T03:25:29.822032Z",
     "iopub.status.idle": "2025-04-19T03:25:30.615335Z",
     "shell.execute_reply": "2025-04-19T03:25:30.614621Z"
    },
    "id": "36c74c8d",
    "outputId": "79e5f253-c92d-44b2-dfef-f178ead8ddb8",
    "papermill": {
     "duration": 0.872667,
     "end_time": "2025-04-19T03:25:30.616827",
     "exception": false,
     "start_time": "2025-04-19T03:25:29.744160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715191f75c6544cdbf73e0d825119688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7362a53babfa4a65ac34c75aa23b2cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3978b2540eef4deaa37540481f31b78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48cba0ab1b94000848eb373e23b2336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6c572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:30.648963Z",
     "iopub.status.busy": "2025-04-19T03:25:30.648634Z",
     "iopub.status.idle": "2025-04-19T03:25:30.684650Z",
     "shell.execute_reply": "2025-04-19T03:25:30.684004Z"
    },
    "id": "0fb6c572",
    "papermill": {
     "duration": 0.053384,
     "end_time": "2025-04-19T03:25:30.686089",
     "exception": false,
     "start_time": "2025-04-19T03:25:30.632705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "PARAGRAPH_SEP_PATTERN = regex.compile(r'(?<=\\n\\n)')\n",
    "LINE_SEP_PATTERN = regex.compile('[\\n]+')\n",
    "PUNCT_PATTERN = regex.compile(r'(?<=[\\p{P}])(?=\\s+)')\n",
    "\n",
    "def truncator(group_encodings):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    input_ids = [tokenizer.cls_token_id]\n",
    "    attention_mask = [1]\n",
    "    n = 0\n",
    "    while n < len(group_encodings):\n",
    "        if len(input_ids) + len(group_encodings[n]['input_ids']) + 1 >= tokenizer.model_max_length:\n",
    "            break\n",
    "        input_ids = [*input_ids, *group_encodings[n]['input_ids']]\n",
    "        attention_mask = [*attention_mask, *group_encodings[n]['attention_mask']]\n",
    "        n += 1\n",
    "\n",
    "    input_ids.append(tokenizer.sep_token_id)\n",
    "    attention_mask.append(1)\n",
    "\n",
    "    pad_length = tokenizer.model_max_length - len(input_ids)\n",
    "    input_ids = [*input_ids, *[tokenizer.pad_token_id]*pad_length]\n",
    "    attention_mask = [*attention_mask, *[0]*pad_length]\n",
    "\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask}, n\n",
    "\n",
    "def tokenizer_custom_truncation(text):\n",
    "  # split text into paragraphs and tokenize\n",
    "    paragraphs = PARAGRAPH_SEP_PATTERN.split(text)\n",
    "    paragraph_encodings = [tokenizer(para, add_special_tokens=False) for para in paragraphs]\n",
    "\n",
    "  # if first paragraph is too long, further split text into lines and tokenize\n",
    "    if len(paragraph_encodings[0]['input_ids']) +2 >= tokenizer.model_max_length:\n",
    "        lines = LINE_SEP_PATTERN.split(paragraphs[0])\n",
    "        line_encodings = [tokenizer(line, add_special_tokens=False) for line in lines]\n",
    "\n",
    "      # if first line is still too long, split first line on punctuation and tokenize\n",
    "        if len(line_encodings[0]['input_ids']) +2 >= tokenizer.model_max_length:\n",
    "            sentences = PUNCT_PATTERN.split(lines[0])\n",
    "            sentence_encodings = [tokenizer(sentence, add_special_tokens=False) for sentence in sentences]\n",
    "\n",
    "          # if first sentence is still too long, just return truncated first sentence\n",
    "            if len(sentence_encodings[0]['input_ids']) +2 >= tokenizer.model_max_length:\n",
    "              return tokenizer(sentences[0], truncation=True, padding='max_length')\n",
    "        # otherwise truncate first line split on sentences\n",
    "            else:\n",
    "              encodings, _ = truncator(sentence_encodings)\n",
    "              return encodings\n",
    "      # otherwise truncate first paragraph split on lines\n",
    "        else:\n",
    "            encodings, _ = truncator(line_encodings)\n",
    "            return encodings\n",
    "  # otherwise truncate whole text split on paragraphs\n",
    "    encodings, _ = truncator(paragraph_encodings)\n",
    "    return encodings\n",
    "\n",
    "def tokenize_list(texts):\n",
    "    encodings = [tokenizer_custom_truncation(text) for text in texts]\n",
    "    return {'input_ids': np.array([e['input_ids'] for e in encodings]),\n",
    "            'attention_mask': np.array([e['attention_mask'] for e in encodings])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce9b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:25:30.720709Z",
     "iopub.status.busy": "2025-04-19T03:25:30.720023Z",
     "iopub.status.idle": "2025-04-19T03:27:09.160350Z",
     "shell.execute_reply": "2025-04-19T03:27:09.159330Z"
    },
    "id": "d4ce9b00",
    "outputId": "f07a0b31-db7e-4205-c0ef-83186c08169b",
    "papermill": {
     "duration": 98.474481,
     "end_time": "2025-04-19T03:27:09.178092",
     "exception": false,
     "start_time": "2025-04-19T03:25:30.703611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 1.33 s, total: 1min 38s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_train_encodings = tokenize_list(full_train['text'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a6ae2",
   "metadata": {
    "id": "084a6ae2",
    "papermill": {
     "duration": 0.01568,
     "end_time": "2025-04-19T03:27:09.209594",
     "exception": false,
     "start_time": "2025-04-19T03:27:09.193914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning using a validation set\n",
    "\n",
    "We now perform hyperparameter tuning as in the previous notebook. This will require a train/val split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285fcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:27:09.243393Z",
     "iopub.status.busy": "2025-04-19T03:27:09.243066Z",
     "iopub.status.idle": "2025-04-19T03:27:09.457586Z",
     "shell.execute_reply": "2025-04-19T03:27:09.456716Z"
    },
    "id": "a285fcc0",
    "papermill": {
     "duration": 0.233657,
     "end_time": "2025-04-19T03:27:09.459285",
     "exception": false,
     "start_time": "2025-04-19T03:27:09.225628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_indices, val_indices = train_test_split(np.arange(len(full_train)), test_size=0.2, random_state=623, stratify=full_train['label'])\n",
    "\n",
    "train_encodings = {'input_ids': full_train_encodings['input_ids'][train_indices,:],\n",
    "                   'attention_mask': full_train_encodings['attention_mask'][train_indices,:]}\n",
    "val_encodings = {'input_ids': full_train_encodings['input_ids'][val_indices,:],\n",
    "                 'attention_mask': full_train_encodings['attention_mask'][val_indices,:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac207c",
   "metadata": {
    "id": "b9ac207c",
    "papermill": {
     "duration": 0.015428,
     "end_time": "2025-04-19T03:27:09.490428",
     "exception": false,
     "start_time": "2025-04-19T03:27:09.475000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now convert our training and validation data into TensorFlow datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a37cc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:27:09.522917Z",
     "iopub.status.busy": "2025-04-19T03:27:09.522121Z",
     "iopub.status.idle": "2025-04-19T03:27:09.528249Z",
     "shell.execute_reply": "2025-04-19T03:27:09.527604Z"
    },
    "id": "51a37cc9",
    "papermill": {
     "duration": 0.023736,
     "end_time": "2025-04-19T03:27:09.529499",
     "exception": false,
     "start_time": "2025-04-19T03:27:09.505763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(encodings, labels, batch_size):\n",
    "    input_ids = tf.convert_to_tensor(encodings['input_ids'], dtype=tf.int32)\n",
    "    attention_mask = tf.convert_to_tensor(encodings['attention_mask'], dtype=tf.int32)\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        ({'input_ids': input_ids, 'attention_mask': attention_mask}, labels)\n",
    "        ).shuffle(buffer_size=len(encodings['input_ids'])).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b7347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:27:09.562488Z",
     "iopub.status.busy": "2025-04-19T03:27:09.561654Z",
     "iopub.status.idle": "2025-04-19T03:27:10.716943Z",
     "shell.execute_reply": "2025-04-19T03:27:10.715910Z"
    },
    "id": "937b7347",
    "outputId": "b6e18f3c-11f5-4deb-fa9e-f1b5abf957cc",
    "papermill": {
     "duration": 1.17306,
     "end_time": "2025-04-19T03:27:10.718497",
     "exception": false,
     "start_time": "2025-04-19T03:27:09.545437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745033230.054287      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1745033230.055133      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = create_dataset(train_encodings, full_train.iloc[train_indices]['label'].values, batch_size)\n",
    "val_dataset = create_dataset(val_encodings, full_train.iloc[val_indices]['label'].values, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b301d4b",
   "metadata": {
    "id": "3b301d4b",
    "papermill": {
     "duration": 0.015085,
     "end_time": "2025-04-19T03:27:10.749331",
     "exception": false,
     "start_time": "2025-04-19T03:27:10.734246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are now ready to train the model. We'll load the model, then set the parameters for the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f388f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:27:10.780892Z",
     "iopub.status.busy": "2025-04-19T03:27:10.780246Z",
     "iopub.status.idle": "2025-04-19T03:27:10.790671Z",
     "shell.execute_reply": "2025-04-19T03:27:10.789898Z"
    },
    "id": "4f388f84",
    "papermill": {
     "duration": 0.02729,
     "end_time": "2025-04-19T03:27:10.791894",
     "exception": false,
     "start_time": "2025-04-19T03:27:10.764604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,TensorBoard\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda, Softmax\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return learning_rate\n",
    "\n",
    "def create_model():\n",
    "    base_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=3)\n",
    "    input_ids = Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "    logits_3_class = base_model([input_ids, attention_mask]).logits\n",
    "    probs_3_class = Softmax(name='softmax_3class')(logits_3_class)\n",
    "\n",
    "    def fuse_probs(probs):\n",
    "        class_0 = probs[:,0]\n",
    "        class_1 = probs[:,1] + probs[:,2]\n",
    "        return tf.stack([class_0, class_1], axis=1)\n",
    "\n",
    "    fused_probs = Lambda(fuse_probs, name='fused_probs')(probs_3_class)\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=fused_probs)\n",
    "\n",
    "    model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
    "                  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_model(model, train, val=None):\n",
    "    history = model.fit(train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[LearningRateScheduler(lr_scheduler),\n",
    "                                   TensorBoard(log_dir=\"logs/fit\", histogram_freq=1, update_freq='batch')],\n",
    "                        validation_data=val,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81198fc",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "417af3805b50457ab0017a1e0755e5cf"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-04-19T03:27:10.822181Z",
     "iopub.status.busy": "2025-04-19T03:27:10.821848Z",
     "iopub.status.idle": "2025-04-19T03:27:17.328532Z",
     "shell.execute_reply": "2025-04-19T03:27:17.327906Z"
    },
    "id": "d81198fc",
    "outputId": "054fb794-e400-4e3a-c744-2b1f56a0ee2e",
    "papermill": {
     "duration": 6.523651,
     "end_time": "2025-04-19T03:27:17.330104",
     "exception": false,
     "start_time": "2025-04-19T03:27:10.806453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417af3805b50457ab0017a1e0755e5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "model_for_val = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d84277-7322-4ed3-bfbc-6232e7a6bb5d",
   "metadata": {
    "id": "18d84277-7322-4ed3-bfbc-6232e7a6bb5d"
   },
   "source": [
    "As in the previous model, I'll begin training at a learning rate of $10^{-5}$, then repeatedly halve the learning rate as I train for further epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87528315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T03:27:17.364624Z",
     "iopub.status.busy": "2025-04-19T03:27:17.364008Z",
     "iopub.status.idle": "2025-04-19T04:26:44.551027Z",
     "shell.execute_reply": "2025-04-19T04:26:44.550229Z"
    },
    "id": "87528315",
    "outputId": "0bc2b7ce-5190-4a82-ea33-3835aad621ac",
    "papermill": {
     "duration": 3567.460767,
     "end_time": "2025-04-19T04:26:44.807380",
     "exception": false,
     "start_time": "2025-04-19T03:27:17.346613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745033257.239707      75 service.cc:148] XLA service 0x7b3091ab0e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745033257.240599      75 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1745033257.240624      75 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1745033257.325182      75 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1745033257.434190      75 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6044/6044 [==============================] - 3566s 586ms/step - loss: 0.3546 - accuracy: 0.9574 - val_loss: 0.3337 - val_accuracy: 0.9787 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc4e5e-dcbe-4026-8867-d1d566c8e5d4",
   "metadata": {
    "id": "0abc4e5e-dcbe-4026-8867-d1d566c8e5d4"
   },
   "source": [
    "We immediately see that both the train and validation loss at one epoch are nearly an order of magnitude higher than in the previous model. The model is struggling to for a decision boundary that incorporates the new text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7c7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:26:45.373668Z",
     "iopub.status.busy": "2025-04-19T04:26:45.373383Z",
     "iopub.status.idle": "2025-04-19T05:26:00.920250Z",
     "shell.execute_reply": "2025-04-19T05:26:00.919415Z"
    },
    "id": "f0b7c7b8",
    "outputId": "8925e9fb-690c-4fee-c0a3-46a31e38f835",
    "papermill": {
     "duration": 3556.450217,
     "end_time": "2025-04-19T05:26:01.510828",
     "exception": false,
     "start_time": "2025-04-19T04:26:45.060611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6044/6044 [==============================] - 3556s 588ms/step - loss: 0.3227 - accuracy: 0.9903 - val_loss: 0.3252 - val_accuracy: 0.9878 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab985d-40b7-45ec-9861-72fa44504638",
   "metadata": {
    "id": "a3ab985d-40b7-45ec-9861-72fa44504638"
   },
   "source": [
    "After the second epoch, the train and validation loss have both improved slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d92e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T05:26:02.753215Z",
     "iopub.status.busy": "2025-04-19T05:26:02.752719Z",
     "iopub.status.idle": "2025-04-19T06:25:19.432585Z",
     "shell.execute_reply": "2025-04-19T06:25:19.431696Z"
    },
    "id": "314d92e5",
    "outputId": "c5f83ca8-1f5c-488d-fd23-b7fb35f331fd",
    "papermill": {
     "duration": 3558.25761,
     "end_time": "2025-04-19T06:25:20.426578",
     "exception": false,
     "start_time": "2025-04-19T05:26:02.168968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6044/6044 [==============================] - 3557s 588ms/step - loss: 0.3191 - accuracy: 0.9940 - val_loss: 0.3253 - val_accuracy: 0.9876 - lr: 2.5000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_for_val, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fc678-8770-45b8-8acf-53259278b05e",
   "metadata": {
    "id": "278fc678-8770-45b8-8acf-53259278b05e"
   },
   "source": [
    "After the third epoch, the train loss has continued to improve, while the validation loss has very slightly increased. I'll stop training at this point to avoid overfitting, then train using the same learning rate schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb27d37",
   "metadata": {
    "id": "4cb27d37",
    "papermill": {
     "duration": 0.957174,
     "end_time": "2025-04-19T06:25:22.248375",
     "exception": false,
     "start_time": "2025-04-19T06:25:21.291201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfe220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:25:24.053326Z",
     "iopub.status.busy": "2025-04-19T06:25:24.053009Z",
     "iopub.status.idle": "2025-04-19T06:25:24.577258Z",
     "shell.execute_reply": "2025-04-19T06:25:24.576271Z"
    },
    "id": "bbcfe220",
    "papermill": {
     "duration": 1.470879,
     "end_time": "2025-04-19T06:25:24.578736",
     "exception": false,
     "start_time": "2025-04-19T06:25:23.107857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "full_train_dataset = create_dataset(full_train_encodings, full_train['label'].values, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de5d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:25:26.402936Z",
     "iopub.status.busy": "2025-04-19T06:25:26.402606Z",
     "iopub.status.idle": "2025-04-19T06:25:28.881069Z",
     "shell.execute_reply": "2025-04-19T06:25:28.880421Z"
    },
    "id": "c0de5d57",
    "outputId": "ce7da40f-03db-465c-a6d5-40bad2b0a5d0",
    "papermill": {
     "duration": 3.444546,
     "end_time": "2025-04-19T06:25:28.882443",
     "exception": false,
     "start_time": "2025-04-19T06:25:25.437897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "model_full = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541187a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:25:30.732739Z",
     "iopub.status.busy": "2025-04-19T06:25:30.732422Z",
     "iopub.status.idle": "2025-04-19T07:33:53.535567Z",
     "shell.execute_reply": "2025-04-19T07:33:53.534640Z"
    },
    "id": "541187a3",
    "outputId": "22df4890-f45b-4c47-e63e-8378b5847b94",
    "papermill": {
     "duration": 4105.074073,
     "end_time": "2025-04-19T07:33:54.798766",
     "exception": false,
     "start_time": "2025-04-19T06:25:29.724693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7555/7555 [==============================] - 4103s 540ms/step - loss: 0.3456 - accuracy: 0.9675 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "fit_model(model_full, full_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2871736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T07:33:57.565357Z",
     "iopub.status.busy": "2025-04-19T07:33:57.565049Z",
     "iopub.status.idle": "2025-04-19T07:34:44.922167Z",
     "shell.execute_reply": "2025-04-19T07:34:44.921122Z"
    },
    "id": "a2871736",
    "papermill": {
     "duration": 48.708326,
     "end_time": "2025-04-19T07:34:44.923906",
     "exception": false,
     "start_time": "2025-04-19T07:33:56.215580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_full.save('model_epoch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d2358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T07:34:47.538458Z",
     "iopub.status.busy": "2025-04-19T07:34:47.538140Z",
     "iopub.status.idle": "2025-04-19T08:42:46.233414Z",
     "shell.execute_reply": "2025-04-19T08:42:46.232704Z"
    },
    "id": "938d2358",
    "outputId": "b73bf53b-3a5d-4c5c-8997-40912eb571f0",
    "papermill": {
     "duration": 4080.063205,
     "end_time": "2025-04-19T08:42:46.234826",
     "exception": false,
     "start_time": "2025-04-19T07:34:46.171621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7555/7555 [==============================] - 4079s 540ms/step - loss: 0.3224 - accuracy: 0.9906 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_full, full_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381451c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T08:42:49.699701Z",
     "iopub.status.busy": "2025-04-19T08:42:49.699404Z",
     "iopub.status.idle": "2025-04-19T08:43:34.621894Z",
     "shell.execute_reply": "2025-04-19T08:43:34.621198Z"
    },
    "id": "0381451c",
    "papermill": {
     "duration": 46.614804,
     "end_time": "2025-04-19T08:43:34.623365",
     "exception": false,
     "start_time": "2025-04-19T08:42:48.008561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_full.save('model_epoch_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a1adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T08:43:37.989768Z",
     "iopub.status.busy": "2025-04-19T08:43:37.989466Z",
     "iopub.status.idle": "2025-04-19T09:51:46.294286Z",
     "shell.execute_reply": "2025-04-19T09:51:46.293544Z"
    },
    "id": "788a1adb",
    "outputId": "f8e327b5-69d7-437f-cd9f-5b72949d02cc",
    "papermill": {
     "duration": 4091.976997,
     "end_time": "2025-04-19T09:51:48.282773",
     "exception": false,
     "start_time": "2025-04-19T08:43:36.305776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7555/7555 [==============================] - 4088s 541ms/step - loss: 0.3196 - accuracy: 0.9936 - lr: 2.5000e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate /= 2\n",
    "fit_model(model_full, full_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836da61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T09:51:52.140985Z",
     "iopub.status.busy": "2025-04-19T09:51:52.140362Z",
     "iopub.status.idle": "2025-04-19T09:52:34.071676Z",
     "shell.execute_reply": "2025-04-19T09:52:34.070697Z"
    },
    "id": "6836da61",
    "papermill": {
     "duration": 43.944775,
     "end_time": "2025-04-19T09:52:34.073280",
     "exception": false,
     "start_time": "2025-04-19T09:51:50.128505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_full.save('model_epoch_3')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6866448,
     "sourceId": 11416885,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23377.763214,
   "end_time": "2025-04-19T09:54:14.371397",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-19T03:24:36.608183",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
